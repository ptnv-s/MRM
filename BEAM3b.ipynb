{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "BEAM3b.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "_kxfdP4hJUPB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "51d15bb1-11be-4ccd-ed38-5b23f6e3cea3"
      },
      "source": [
        "!pip install tensorflow-addons==0.11.2"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow-addons==0.11.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f9/9b/198d3745f937d1ab244eabc4ffdc420f84f2b86d6d8f0937f3f0acc1b258/tensorflow_addons-0.11.2-cp37-cp37m-manylinux2010_x86_64.whl (1.1MB)\n",
            "\r\u001b[K     |▎                               | 10kB 15.4MB/s eta 0:00:01\r\u001b[K     |▋                               | 20kB 22.4MB/s eta 0:00:01\r\u001b[K     |█                               | 30kB 22.2MB/s eta 0:00:01\r\u001b[K     |█▏                              | 40kB 20.2MB/s eta 0:00:01\r\u001b[K     |█▌                              | 51kB 22.3MB/s eta 0:00:01\r\u001b[K     |█▉                              | 61kB 16.2MB/s eta 0:00:01\r\u001b[K     |██                              | 71kB 16.8MB/s eta 0:00:01\r\u001b[K     |██▍                             | 81kB 17.5MB/s eta 0:00:01\r\u001b[K     |██▊                             | 92kB 15.7MB/s eta 0:00:01\r\u001b[K     |███                             | 102kB 16.9MB/s eta 0:00:01\r\u001b[K     |███▎                            | 112kB 16.9MB/s eta 0:00:01\r\u001b[K     |███▋                            | 122kB 16.9MB/s eta 0:00:01\r\u001b[K     |███▉                            | 133kB 16.9MB/s eta 0:00:01\r\u001b[K     |████▏                           | 143kB 16.9MB/s eta 0:00:01\r\u001b[K     |████▌                           | 153kB 16.9MB/s eta 0:00:01\r\u001b[K     |████▊                           | 163kB 16.9MB/s eta 0:00:01\r\u001b[K     |█████                           | 174kB 16.9MB/s eta 0:00:01\r\u001b[K     |█████▍                          | 184kB 16.9MB/s eta 0:00:01\r\u001b[K     |█████▋                          | 194kB 16.9MB/s eta 0:00:01\r\u001b[K     |██████                          | 204kB 16.9MB/s eta 0:00:01\r\u001b[K     |██████▎                         | 215kB 16.9MB/s eta 0:00:01\r\u001b[K     |██████▌                         | 225kB 16.9MB/s eta 0:00:01\r\u001b[K     |██████▉                         | 235kB 16.9MB/s eta 0:00:01\r\u001b[K     |███████▏                        | 245kB 16.9MB/s eta 0:00:01\r\u001b[K     |███████▌                        | 256kB 16.9MB/s eta 0:00:01\r\u001b[K     |███████▊                        | 266kB 16.9MB/s eta 0:00:01\r\u001b[K     |████████                        | 276kB 16.9MB/s eta 0:00:01\r\u001b[K     |████████▍                       | 286kB 16.9MB/s eta 0:00:01\r\u001b[K     |████████▋                       | 296kB 16.9MB/s eta 0:00:01\r\u001b[K     |█████████                       | 307kB 16.9MB/s eta 0:00:01\r\u001b[K     |█████████▎                      | 317kB 16.9MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 327kB 16.9MB/s eta 0:00:01\r\u001b[K     |█████████▉                      | 337kB 16.9MB/s eta 0:00:01\r\u001b[K     |██████████▏                     | 348kB 16.9MB/s eta 0:00:01\r\u001b[K     |██████████▍                     | 358kB 16.9MB/s eta 0:00:01\r\u001b[K     |██████████▊                     | 368kB 16.9MB/s eta 0:00:01\r\u001b[K     |███████████                     | 378kB 16.9MB/s eta 0:00:01\r\u001b[K     |███████████▎                    | 389kB 16.9MB/s eta 0:00:01\r\u001b[K     |███████████▋                    | 399kB 16.9MB/s eta 0:00:01\r\u001b[K     |████████████                    | 409kB 16.9MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 419kB 16.9MB/s eta 0:00:01\r\u001b[K     |████████████▌                   | 430kB 16.9MB/s eta 0:00:01\r\u001b[K     |████████████▉                   | 440kB 16.9MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 450kB 16.9MB/s eta 0:00:01\r\u001b[K     |█████████████▍                  | 460kB 16.9MB/s eta 0:00:01\r\u001b[K     |█████████████▊                  | 471kB 16.9MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 481kB 16.9MB/s eta 0:00:01\r\u001b[K     |██████████████▎                 | 491kB 16.9MB/s eta 0:00:01\r\u001b[K     |██████████████▋                 | 501kB 16.9MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 512kB 16.9MB/s eta 0:00:01\r\u001b[K     |███████████████▏                | 522kB 16.9MB/s eta 0:00:01\r\u001b[K     |███████████████▌                | 532kB 16.9MB/s eta 0:00:01\r\u001b[K     |███████████████▉                | 542kB 16.9MB/s eta 0:00:01\r\u001b[K     |████████████████                | 552kB 16.9MB/s eta 0:00:01\r\u001b[K     |████████████████▍               | 563kB 16.9MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 573kB 16.9MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 583kB 16.9MB/s eta 0:00:01\r\u001b[K     |█████████████████▎              | 593kB 16.9MB/s eta 0:00:01\r\u001b[K     |█████████████████▋              | 604kB 16.9MB/s eta 0:00:01\r\u001b[K     |█████████████████▉              | 614kB 16.9MB/s eta 0:00:01\r\u001b[K     |██████████████████▏             | 624kB 16.9MB/s eta 0:00:01\r\u001b[K     |██████████████████▌             | 634kB 16.9MB/s eta 0:00:01\r\u001b[K     |██████████████████▊             | 645kB 16.9MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 655kB 16.9MB/s eta 0:00:01\r\u001b[K     |███████████████████▍            | 665kB 16.9MB/s eta 0:00:01\r\u001b[K     |███████████████████▋            | 675kB 16.9MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 686kB 16.9MB/s eta 0:00:01\r\u001b[K     |████████████████████▎           | 696kB 16.9MB/s eta 0:00:01\r\u001b[K     |████████████████████▌           | 706kB 16.9MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 716kB 16.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████▏          | 727kB 16.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████▍          | 737kB 16.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████▊          | 747kB 16.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 757kB 16.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████▍         | 768kB 16.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████▋         | 778kB 16.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 788kB 16.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████▎        | 798kB 16.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████▌        | 808kB 16.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 819kB 16.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████▏       | 829kB 16.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████▍       | 839kB 16.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 849kB 16.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 860kB 16.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▎      | 870kB 16.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▋      | 880kB 16.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 890kB 16.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 901kB 16.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 911kB 16.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▉     | 921kB 16.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 931kB 16.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▍    | 942kB 16.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▊    | 952kB 16.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 962kB 16.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▎   | 972kB 16.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▋   | 983kB 16.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 993kB 16.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 1.0MB 16.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▌  | 1.0MB 16.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▉  | 1.0MB 16.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 1.0MB 16.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▍ | 1.0MB 16.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▊ | 1.1MB 16.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 1.1MB 16.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▎| 1.1MB 16.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▋| 1.1MB 16.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▉| 1.1MB 16.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 1.1MB 16.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: typeguard>=2.7 in /usr/local/lib/python3.7/dist-packages (from tensorflow-addons==0.11.2) (2.7.1)\n",
            "Installing collected packages: tensorflow-addons\n",
            "Successfully installed tensorflow-addons-0.11.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tnxXKDjq3jEL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ca561602-69f7-4de6-b0c4-0b100e0aa335"
      },
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_addons as tfa\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.ticker as ticker\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import unicodedata\n",
        "import re\n",
        "import numpy as np\n",
        "import os\n",
        "import io\n",
        "import time\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow_addons/utils/ensure_tf_install.py:68: UserWarning: Tensorflow Addons supports using Python ops for all Tensorflow versions above or equal to 2.2.0 and strictly below 2.4.0 (nightly versions are not supported). \n",
            " The versions of TensorFlow you are currently using is 2.4.1 and is not supported. \n",
            "Some things might work, some things might not.\n",
            "If you were to encounter a bug, do not file an issue.\n",
            "If you want to make sure you're using a tested and supported configuration, either change the TensorFlow version or the TensorFlow Addons's version. \n",
            "You can find the compatibility matrix in TensorFlow Addon's readme:\n",
            "https://github.com/tensorflow/addons\n",
            "  UserWarning,\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PvRnGWnvXm6l"
      },
      "source": [
        "def download_nmt():\n",
        "    path_to_zip = tf.keras.utils.get_file(\n",
        "    'spa-eng.zip', origin='http://storage.googleapis.com/download.tensorflow.org/data/spa-eng.zip',\n",
        "    extract=True)\n",
        "\n",
        "    path_to_file = os.path.dirname(path_to_zip)+\"/spa-eng/spa.txt\"\n",
        "    return path_to_file\n"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JMAHz7kJXc5N"
      },
      "source": [
        "class NMTDataset:\n",
        "    def __init__(self, problem_type='en-spa'):\n",
        "        self.problem_type = 'en-spa'\n",
        "        self.inp_lang_tokenizer = None\n",
        "        self.targ_lang_tokenizer = None\n",
        "    \n",
        "\n",
        "    def unicode_to_ascii(self, s):\n",
        "        return ''.join(c for c in unicodedata.normalize('NFD', s) if unicodedata.category(c) != 'Mn')\n",
        "\n",
        "    ## Step 1 and Step 2 \n",
        "    def preprocess_sentence(self, w):\n",
        "        w = self.unicode_to_ascii(w.lower().strip())\n",
        "\n",
        "        # creating a space between a word and the punctuation following it\n",
        "        # eg: \"he is a boy.\" => \"he is a boy .\"\n",
        "        # Reference:- https://stackoverflow.com/questions/3645931/python-padding-punctuation-with-white-spaces-keeping-punctuation\n",
        "        w = re.sub(r\"([?.!,¿])\", r\" \\1 \", w)\n",
        "        w = re.sub(r'[\" \"]+', \" \", w)\n",
        "\n",
        "        # replacing everything with space except (a-z, A-Z, \".\", \"?\", \"!\", \",\")\n",
        "        w = re.sub(r\"[^a-zA-Z?.!,¿]+\", \" \", w)\n",
        "\n",
        "        w = w.strip()\n",
        "\n",
        "        # adding a start and an end token to the sentence\n",
        "        # so that the model know when to start and stop predicting.\n",
        "        w = '<start> ' + w + ' <end>'\n",
        "        return w\n",
        "    \n",
        "    def create_dataset(self, path, num_examples):\n",
        "        # path : path to spa-eng.txt file\n",
        "        # num_examples : Limit the total number of training example for faster training (set num_examples = len(lines) to use full data)\n",
        "        lines = io.open(path, encoding='UTF-8').read().strip().split('\\n')\n",
        "        word_pairs = [[self.preprocess_sentence(w) for w in l.split('\\t')]  for l in lines[:num_examples]]\n",
        "\n",
        "        return zip(*word_pairs)\n",
        "\n",
        "    # Step 3 and Step 4\n",
        "    def tokenize(self, lang):\n",
        "        # lang = list of sentences in a language\n",
        "        \n",
        "        # print(len(lang), \"example sentence: {}\".format(lang[0]))\n",
        "        lang_tokenizer = tf.keras.preprocessing.text.Tokenizer(filters='', oov_token='<OOV>')\n",
        "        lang_tokenizer.fit_on_texts(lang)\n",
        "\n",
        "        ## tf.keras.preprocessing.text.Tokenizer.texts_to_sequences converts string (w1, w2, w3, ......, wn) \n",
        "        ## to a list of correspoding integer ids of words (id_w1, id_w2, id_w3, ...., id_wn)\n",
        "        tensor = lang_tokenizer.texts_to_sequences(lang) \n",
        "\n",
        "        ## tf.keras.preprocessing.sequence.pad_sequences takes argument a list of integer id sequences \n",
        "        ## and pads the sequences to match the longest sequences in the given input\n",
        "        tensor = tf.keras.preprocessing.sequence.pad_sequences(tensor, padding='post')\n",
        "\n",
        "        return tensor, lang_tokenizer\n",
        "\n",
        "    def load_dataset(self, path, num_examples=None):\n",
        "        # creating cleaned input, output pairs\n",
        "        targ_lang, inp_lang = self.create_dataset(path, num_examples)\n",
        "\n",
        "        input_tensor, inp_lang_tokenizer = self.tokenize(inp_lang)\n",
        "        target_tensor, targ_lang_tokenizer = self.tokenize(targ_lang)\n",
        "\n",
        "        return input_tensor, target_tensor, inp_lang_tokenizer, targ_lang_tokenizer\n",
        "\n",
        "    def call(self, num_examples, BUFFER_SIZE, BATCH_SIZE):\n",
        "        file_path = download_nmt()\n",
        "        input_tensor, target_tensor, self.inp_lang_tokenizer, self.targ_lang_tokenizer = self.load_dataset(file_path, num_examples)\n",
        "        \n",
        "        input_tensor_train, input_tensor_val, target_tensor_train, target_tensor_val = train_test_split(input_tensor, target_tensor, test_size=0.2)\n",
        "\n",
        "        train_dataset = tf.data.Dataset.from_tensor_slices((input_tensor_train, target_tensor_train))\n",
        "        train_dataset = train_dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE, drop_remainder=True)\n",
        "\n",
        "        val_dataset = tf.data.Dataset.from_tensor_slices((input_tensor_val, target_tensor_val))\n",
        "        val_dataset = val_dataset.batch(BATCH_SIZE, drop_remainder=True)\n",
        "\n",
        "        return train_dataset, val_dataset, self.inp_lang_tokenizer, self.targ_lang_tokenizer"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EIW4NVBmJ25k",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "82632f9e-88d2-4478-88d3-4c24cf852941"
      },
      "source": [
        "BUFFER_SIZE = 32000\n",
        "BATCH_SIZE = 256\n",
        "# Let's limit the #training examples for faster training\n",
        "num_examples = 30000\n",
        "\n",
        "dataset_creator = NMTDataset('en-spa')\n",
        "train_dataset, val_dataset, inp_lang, targ_lang = dataset_creator.call(num_examples, BUFFER_SIZE, BATCH_SIZE)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from http://storage.googleapis.com/download.tensorflow.org/data/spa-eng.zip\n",
            "2646016/2638744 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w2lCTy4vKOkB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "875f8a5e-e695-4631-af20-2443bd4b74b7"
      },
      "source": [
        "example_input_batch, example_target_batch = next(iter(train_dataset))\n",
        "example_input_batch.shape, example_target_batch.shape"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(TensorShape([256, 16]), TensorShape([256, 11]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TqHsArVZ3jFS"
      },
      "source": [
        "vocab_inp_size = len(inp_lang.word_index)+1\n",
        "vocab_tar_size = len(targ_lang.word_index)+1\n",
        "max_length_input = example_input_batch.shape[1]\n",
        "max_length_output = example_target_batch.shape[1]\n",
        "\n",
        "embedding_dim = 256\n",
        "units = 1000\n",
        "steps_per_epoch = num_examples//BATCH_SIZE\n"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g-yY9c6aIu1h",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "890a510b-60eb-4ff6-9109-1e6adf5d1ae9"
      },
      "source": [
        "print(\"max_length_spanish, max_length_english, vocab_size_spanish, vocab_size_english\")\n",
        "max_length_input, max_length_output, vocab_inp_size, vocab_tar_size"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "max_length_spanish, max_length_english, vocab_size_spanish, vocab_size_english\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(16, 11, 9415, 4936)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nZ2rI24i3jFg"
      },
      "source": [
        "##### \n",
        "\n",
        "class Encoder(tf.keras.Model):\n",
        "  def __init__(self, vocab_size, embedding_dim, enc_units, batch_sz):\n",
        "    super(Encoder, self).__init__()\n",
        "    self.batch_sz = batch_sz\n",
        "    self.enc_units = enc_units\n",
        "    self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
        "\n",
        "    ##-------- LSTM layer in Encoder ------- ##\n",
        "    self.lstm_layer = tf.keras.layers.LSTM(self.enc_units,\n",
        "                                   return_sequences=True,\n",
        "                                   return_state=True,\n",
        "                                   recurrent_initializer='glorot_uniform')\n",
        "    \n",
        "\n",
        "\n",
        "  def call(self, x, hidden):\n",
        "    x = self.embedding(x)\n",
        "    output, h, c = self.lstm_layer(x, initial_state = hidden)\n",
        "    return output, h, c\n",
        "\n",
        "  def initialize_hidden_state(self):\n",
        "    return [tf.zeros((self.batch_sz, self.enc_units)), tf.zeros((self.batch_sz, self.enc_units))] "
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "60gSVh05Jl6l",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b2094cb2-4859-4ff1-d05c-da88b0f37dfb"
      },
      "source": [
        "## Test Encoder Stack\n",
        "\n",
        "encoder = Encoder(vocab_inp_size, embedding_dim, units, BATCH_SIZE)\n",
        "\n",
        "\n",
        "# sample input\n",
        "sample_hidden = encoder.initialize_hidden_state()\n",
        "sample_output, sample_h, sample_c = encoder(example_input_batch, sample_hidden)\n",
        "print ('Encoder output shape: (batch size, sequence length, units) {}'.format(sample_output.shape))\n",
        "print ('Encoder h vecotr shape: (batch size, units) {}'.format(sample_h.shape))\n",
        "print ('Encoder c vector shape: (batch size, units) {}'.format(sample_c.shape))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Encoder output shape: (batch size, sequence length, units) (256, 16, 1000)\n",
            "Encoder h vecotr shape: (batch size, units) (256, 1000)\n",
            "Encoder c vector shape: (batch size, units) (256, 1000)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yJ_B3mhW3jFk"
      },
      "source": [
        "class Decoder(tf.keras.Model):\n",
        "  def __init__(self, vocab_size, embedding_dim, dec_units, batch_sz, attention_type='luong'):\n",
        "    super(Decoder, self).__init__()\n",
        "    self.batch_sz = batch_sz\n",
        "    self.dec_units = dec_units\n",
        "    self.attention_type = attention_type\n",
        "    \n",
        "    # Embedding Layer\n",
        "    self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
        "    \n",
        "    #Final Dense layer on which softmax will be applied\n",
        "    self.fc = tf.keras.layers.Dense(vocab_size)\n",
        "\n",
        "    # Define the fundamental cell for decoder recurrent structure\n",
        "    self.decoder_rnn_cell = tf.keras.layers.LSTMCell(self.dec_units)\n",
        "   \n",
        "\n",
        "\n",
        "    # Sampler\n",
        "    self.sampler = tfa.seq2seq.sampler.TrainingSampler()\n",
        "\n",
        "    # Create attention mechanism with memory = None\n",
        "    self.attention_mechanism = self.build_attention_mechanism(self.dec_units, \n",
        "                                                              None, self.batch_sz*[max_length_input], self.attention_type)\n",
        "\n",
        "    # Wrap attention mechanism with the fundamental rnn cell of decoder\n",
        "    self.rnn_cell = self.build_rnn_cell(batch_sz)\n",
        "\n",
        "    # Define the decoder with respect to fundamental rnn cell\n",
        "    self.decoder = tfa.seq2seq.BasicDecoder(self.rnn_cell, sampler=self.sampler, output_layer=self.fc)\n",
        "\n",
        "    \n",
        "  def build_rnn_cell(self, batch_sz):\n",
        "    rnn_cell = tfa.seq2seq.AttentionWrapper(self.decoder_rnn_cell, \n",
        "                                  self.attention_mechanism, attention_layer_size=self.dec_units)\n",
        "    return rnn_cell\n",
        "\n",
        "  def build_attention_mechanism(self, dec_units, memory, memory_sequence_length, attention_type='luong'):\n",
        "    # ------------- #\n",
        "    # typ: Which sort of attention (Bahdanau, Luong)\n",
        "    # dec_units: final dimension of attention outputs \n",
        "    # memory: encoder hidden states of shape (batch_size, max_length_input, enc_units)\n",
        "    # memory_sequence_length: 1d array of shape (batch_size) with every element set to max_length_input (for masking purpose)\n",
        "\n",
        "    if(attention_type=='bahdanau'):\n",
        "      return tfa.seq2seq.BahdanauAttention(units=dec_units, memory=memory, memory_sequence_length=memory_sequence_length)\n",
        "    else:\n",
        "      return tfa.seq2seq.LuongAttention(units=dec_units, memory=memory, memory_sequence_length=memory_sequence_length)\n",
        "\n",
        "  def build_initial_state(self, batch_sz, encoder_state, Dtype):\n",
        "    decoder_initial_state = self.rnn_cell.get_initial_state(batch_size=batch_sz, dtype=Dtype)\n",
        "    decoder_initial_state = decoder_initial_state.clone(cell_state=encoder_state)\n",
        "    return decoder_initial_state\n",
        "\n",
        "\n",
        "  def call(self, inputs, initial_state):\n",
        "    x = self.embedding(inputs)\n",
        "    outputs, _, _ = self.decoder(x, initial_state=initial_state, sequence_length=self.batch_sz*[max_length_output-1])\n",
        "    return outputs\n"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DaiO0Z6_Ml1c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1ea216b9-4577-4041-d8b3-7de2039f68b0"
      },
      "source": [
        "# Test decoder stack\n",
        "\n",
        "decoder = Decoder(vocab_tar_size, embedding_dim, units, BATCH_SIZE, 'bahdanau')\n",
        "sample_x = tf.random.uniform((BATCH_SIZE, max_length_output))\n",
        "decoder.attention_mechanism.setup_memory(sample_output)\n",
        "initial_state = decoder.build_initial_state(BATCH_SIZE, [sample_h, sample_c], tf.float32)\n",
        "\n",
        "\n",
        "sample_decoder_outputs = decoder(sample_x, initial_state)\n",
        "\n",
        "print(\"Decoder Outputs Shape: \", sample_decoder_outputs.rnn_output.shape)\n"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Decoder Outputs Shape:  (256, 10, 4936)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WmTHr5iV3jFr"
      },
      "source": [
        "optimizer = tf.keras.optimizers.Adadelta()\n",
        "\n",
        "\n",
        "def loss_function(real, pred):\n",
        "  # real shape = (BATCH_SIZE, max_length_output)\n",
        "  # pred shape = (BATCH_SIZE, max_length_output, tar_vocab_size )\n",
        "  cross_entropy = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True, reduction='none')\n",
        "  loss = cross_entropy(y_true=real, y_pred=pred)\n",
        "  mask = tf.logical_not(tf.math.equal(real,0))   #output 0 for y=0 else output 1\n",
        "  mask = tf.cast(mask, dtype=loss.dtype)  \n",
        "  loss = mask* loss\n",
        "  loss = tf.reduce_mean(loss)\n",
        "  return loss  "
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zj8bXQTgNwrF"
      },
      "source": [
        "checkpoint_dir = './training_checkpoints'\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
        "checkpoint = tf.train.Checkpoint(optimizer=optimizer,\n",
        "                                 encoder=encoder,\n",
        "                                 decoder=decoder)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sC9ArXSsVfqn"
      },
      "source": [
        "@tf.function\n",
        "def train_step(inp, targ, enc_hidden):\n",
        "  loss = 0\n",
        "\n",
        "  with tf.GradientTape() as tape:\n",
        "    enc_output, enc_h, enc_c = encoder(inp, enc_hidden)\n",
        "\n",
        "\n",
        "    dec_input = targ[ : , :-1 ] # Ignore <end> token\n",
        "    real = targ[ : , 1: ]         # ignore <start> token\n",
        "\n",
        "    # Set the AttentionMechanism object with encoder_outputs\n",
        "    decoder.attention_mechanism.setup_memory(enc_output)\n",
        "\n",
        "    # Create AttentionWrapperState as initial_state for decoder\n",
        "    decoder_initial_state = decoder.build_initial_state(BATCH_SIZE, [enc_h, enc_c], tf.float32)\n",
        "    pred = decoder(dec_input, decoder_initial_state)\n",
        "    logits = pred.rnn_output\n",
        "    loss = loss_function(real, logits)\n",
        "\n",
        "  variables = encoder.trainable_variables + decoder.trainable_variables\n",
        "  gradients = tape.gradient(loss, variables)\n",
        "  optimizer.apply_gradients(zip(gradients, variables))\n",
        "\n",
        "  return loss"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ddefjBMa3jF0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "43a31d43-4027-4952-bf2c-2ef84d8e11dd"
      },
      "source": [
        "EPOCHS = 20\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "  start = time.time()\n",
        "\n",
        "  enc_hidden = encoder.initialize_hidden_state()\n",
        "  total_loss = 0\n",
        "  # print(enc_hidden[0].shape, enc_hidden[1].shape)\n",
        "\n",
        "  for (batch, (inp, targ)) in enumerate(train_dataset.take(steps_per_epoch)):\n",
        "    batch_loss = train_step(inp, targ, enc_hidden)\n",
        "    total_loss += batch_loss\n",
        "\n",
        "    if batch % 100 == 0:\n",
        "      print('Epoch {} Batch {} Loss {:.4f}'.format(epoch + 1,\n",
        "                                                   batch,\n",
        "                                                   batch_loss.numpy()))\n",
        "  # saving (checkpoint) the model every 2 epochs\n",
        "  if (epoch + 1) % 2 == 0:\n",
        "    checkpoint.save(file_prefix = checkpoint_prefix)\n",
        "\n",
        "  print('Epoch {} Loss {:.4f}'.format(epoch + 1,\n",
        "                                      total_loss / steps_per_epoch))\n",
        "  print('Time taken for 1 epoch {} sec\\n'.format(time.time() - start))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1 Batch 0 Loss 5.0029\n",
            "Epoch 1 Loss 4.0445\n",
            "Time taken for 1 epoch 22.742438316345215 sec\n",
            "\n",
            "Epoch 2 Batch 0 Loss 5.0855\n",
            "Epoch 2 Loss 4.0443\n",
            "Time taken for 1 epoch 15.189224004745483 sec\n",
            "\n",
            "Epoch 3 Batch 0 Loss 5.1016\n",
            "Epoch 3 Loss 4.0436\n",
            "Time taken for 1 epoch 14.558551788330078 sec\n",
            "\n",
            "Epoch 4 Batch 0 Loss 5.0180\n",
            "Epoch 4 Loss 4.0433\n",
            "Time taken for 1 epoch 15.483413457870483 sec\n",
            "\n",
            "Epoch 5 Batch 0 Loss 5.1835\n",
            "Epoch 5 Loss 4.0420\n",
            "Time taken for 1 epoch 15.106914758682251 sec\n",
            "\n",
            "Epoch 6 Batch 0 Loss 5.0965\n",
            "Epoch 6 Loss 4.0425\n",
            "Time taken for 1 epoch 15.757633924484253 sec\n",
            "\n",
            "Epoch 7 Batch 0 Loss 5.1391\n",
            "Epoch 7 Loss 4.0418\n",
            "Time taken for 1 epoch 15.21297574043274 sec\n",
            "\n",
            "Epoch 8 Batch 0 Loss 5.0753\n",
            "Epoch 8 Loss 4.0417\n",
            "Time taken for 1 epoch 16.157206535339355 sec\n",
            "\n",
            "Epoch 9 Batch 0 Loss 5.0680\n",
            "Epoch 9 Loss 4.0400\n",
            "Time taken for 1 epoch 15.646981239318848 sec\n",
            "\n",
            "Epoch 10 Batch 0 Loss 5.0673\n",
            "Epoch 10 Loss 4.0396\n",
            "Time taken for 1 epoch 16.001773595809937 sec\n",
            "\n",
            "Epoch 11 Batch 0 Loss 5.0965\n",
            "Epoch 11 Loss 4.0403\n",
            "Time taken for 1 epoch 15.208920955657959 sec\n",
            "\n",
            "Epoch 12 Batch 0 Loss 5.0924\n",
            "Epoch 12 Loss 4.0387\n",
            "Time taken for 1 epoch 15.832812786102295 sec\n",
            "\n",
            "Epoch 13 Batch 0 Loss 5.0220\n",
            "Epoch 13 Loss 4.0379\n",
            "Time taken for 1 epoch 15.355184316635132 sec\n",
            "\n",
            "Epoch 14 Batch 0 Loss 5.1142\n",
            "Epoch 14 Loss 4.0378\n",
            "Time taken for 1 epoch 16.01978635787964 sec\n",
            "\n",
            "Epoch 15 Batch 0 Loss 5.0702\n",
            "Epoch 15 Loss 4.0364\n",
            "Time taken for 1 epoch 15.396701335906982 sec\n",
            "\n",
            "Epoch 16 Batch 0 Loss 5.0895\n",
            "Epoch 16 Loss 4.0360\n",
            "Time taken for 1 epoch 15.988059997558594 sec\n",
            "\n",
            "Epoch 17 Batch 0 Loss 5.1682\n",
            "Epoch 17 Loss 4.0356\n",
            "Time taken for 1 epoch 15.411277770996094 sec\n",
            "\n",
            "Epoch 18 Batch 0 Loss 5.0976\n",
            "Epoch 18 Loss 4.0346\n",
            "Time taken for 1 epoch 16.124149084091187 sec\n",
            "\n",
            "Epoch 19 Batch 0 Loss 5.0270\n",
            "Epoch 19 Loss 4.0339\n",
            "Time taken for 1 epoch 15.368848323822021 sec\n",
            "\n",
            "Epoch 20 Batch 0 Loss 5.0063\n",
            "Epoch 20 Loss 4.0340\n",
            "Time taken for 1 epoch 15.944667339324951 sec\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mU3Ce8M6I3rz"
      },
      "source": [
        "## Use tf-addons BasicDecoder for decoding\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EbQpyYs13jF_"
      },
      "source": [
        "def evaluate_sentence(sentence):\n",
        "  sentence = dataset_creator.preprocess_sentence(sentence)\n",
        "\n",
        "  inputs = [inp_lang.word_index[i] for i in sentence.split(' ')]\n",
        "  inputs = tf.keras.preprocessing.sequence.pad_sequences([inputs],\n",
        "                                                          maxlen=max_length_input,\n",
        "                                                          padding='post')\n",
        "  inputs = tf.convert_to_tensor(inputs)\n",
        "  inference_batch_size = inputs.shape[0]\n",
        "  result = ''\n",
        "\n",
        "  enc_start_state = [tf.zeros((inference_batch_size, units)), tf.zeros((inference_batch_size,units))]\n",
        "  enc_out, enc_h, enc_c = encoder(inputs, enc_start_state)\n",
        "\n",
        "  dec_h = enc_h\n",
        "  dec_c = enc_c\n",
        "\n",
        "  start_tokens = tf.fill([inference_batch_size], targ_lang.word_index['<start>'])\n",
        "  end_token = targ_lang.word_index['<end>']\n",
        "\n",
        "  greedy_sampler = tfa.seq2seq.GreedyEmbeddingSampler()\n",
        "\n",
        "  # Instantiate BasicDecoder object\n",
        "  decoder_instance = tfa.seq2seq.BasicDecoder(cell=decoder.rnn_cell, sampler=greedy_sampler, output_layer=decoder.fc)\n",
        "  # Setup Memory in decoder stack\n",
        "  decoder.attention_mechanism.setup_memory(enc_out)\n",
        "\n",
        "  # set decoder_initial_state\n",
        "  decoder_initial_state = decoder.build_initial_state(inference_batch_size, [enc_h, enc_c], tf.float32)\n",
        "\n",
        "\n",
        "  ### Since the BasicDecoder wraps around Decoder's rnn cell only, you have to ensure that the inputs to BasicDecoder \n",
        "  ### decoding step is output of embedding layer. tfa.seq2seq.GreedyEmbeddingSampler() takes care of this. \n",
        "  ### You only need to get the weights of embedding layer, which can be done by decoder.embedding.variables[0] and pass this callabble to BasicDecoder's call() function\n",
        "\n",
        "  decoder_embedding_matrix = decoder.embedding.variables[0]\n",
        "  \n",
        "  outputs, _, _ = decoder_instance(decoder_embedding_matrix, start_tokens = start_tokens, end_token= end_token, initial_state=decoder_initial_state)\n",
        "  return outputs.sample_id.numpy()\n",
        "\n",
        "def translate(sentence):\n",
        "  result = evaluate_sentence(sentence)\n",
        "  print(result)\n",
        "  result = targ_lang.sequences_to_texts(result)\n",
        "  print('Input: %s' % (sentence))\n",
        "  print('Predicted translation: {}'.format(result))"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UJpT9D5_OgP6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "50792bc4-db14-4d56-c0ed-62c71c931df3"
      },
      "source": [
        "# restoring the latest checkpoint in checkpoint_dir\n",
        "checkpoint.restore(tf.train.latest_checkpoint(checkpoint_dir))"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7fa80b5da850>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WYmYhNN_faR5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f9fd67e0-8c66-4709-ee37-0260674298f1"
      },
      "source": [
        "translate(u'hace mucho frio aqui.')"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[3]]\n",
            "Input: hace mucho frio aqui.\n",
            "Predicted translation: ['<end>']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zSx2iM36EZQZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a44f2e45-b9e0-4a21-f7e2-8dab2eb551f5"
      },
      "source": [
        "translate(u'esta es mi vida.')"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[3]]\n",
            "Input: esta es mi vida.\n",
            "Predicted translation: ['<end>']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A3LLCx3ZE0Ls",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2e1b0b83-d086-41db-8047-a01880012848"
      },
      "source": [
        "translate(u'¿todavia estan en casa?')"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[3]]\n",
            "Input: ¿todavia estan en casa?\n",
            "Predicted translation: ['<end>']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DUQVLVqUE1YW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3790cc33-2188-455b-8c89-e7742f96799c"
      },
      "source": [
        "# wrong translation\n",
        "translate(u'trata de averiguarlo.')"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[3]]\n",
            "Input: trata de averiguarlo.\n",
            "Predicted translation: ['<end>']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AJ-RTQ0hsJNL"
      },
      "source": [
        "def beam_evaluate_sentence(sentence, beam_width=5):\n",
        "  sentence = dataset_creator.preprocess_sentence(sentence)\n",
        "\n",
        "  inputs = [inp_lang.word_index[i] for i in sentence.split(' ')]\n",
        "  inputs = tf.keras.preprocessing.sequence.pad_sequences([inputs],\n",
        "                                                          maxlen=max_length_input,\n",
        "                                                          padding='post')\n",
        "  inputs = tf.convert_to_tensor(inputs)\n",
        "  inference_batch_size = inputs.shape[0]\n",
        "  result = ''\n",
        "\n",
        "  enc_start_state = [tf.zeros((inference_batch_size, units)), tf.zeros((inference_batch_size,units))]\n",
        "  enc_out, enc_h, enc_c = encoder(inputs, enc_start_state)\n",
        "\n",
        "  dec_h = enc_h\n",
        "  dec_c = enc_c\n",
        "\n",
        "  start_tokens = tf.fill([inference_batch_size], targ_lang.word_index['<start>'])\n",
        "  end_token = targ_lang.word_index['<end>']\n",
        "\n",
        "  # From official documentation\n",
        "  # NOTE If you are using the BeamSearchDecoder with a cell wrapped in AttentionWrapper, then you must ensure that:\n",
        "  # The encoder output has been tiled to beam_width via tfa.seq2seq.tile_batch (NOT tf.tile).\n",
        "  # The batch_size argument passed to the get_initial_state method of this wrapper is equal to true_batch_size * beam_width.\n",
        "  # The initial state created with get_initial_state above contains a cell_state value containing properly tiled final state from the encoder.\n",
        "\n",
        "  enc_out = tfa.seq2seq.tile_batch(enc_out, multiplier=beam_width)\n",
        "  decoder.attention_mechanism.setup_memory(enc_out)\n",
        "  print(\"beam_with * [batch_size, max_length_input, rnn_units] :  3 * [1, 16, 1024]] :\", enc_out.shape)\n",
        "\n",
        "  # set decoder_inital_state which is an AttentionWrapperState considering beam_width\n",
        "  hidden_state = tfa.seq2seq.tile_batch([enc_h, enc_c], multiplier=beam_width)\n",
        "  decoder_initial_state = decoder.rnn_cell.get_initial_state(batch_size=beam_width*inference_batch_size, dtype=tf.float32)\n",
        "  decoder_initial_state = decoder_initial_state.clone(cell_state=hidden_state)\n",
        "\n",
        "  # Instantiate BeamSearchDecoder\n",
        "  decoder_instance = tfa.seq2seq.BeamSearchDecoder(decoder.rnn_cell,beam_width=beam_width, output_layer=decoder.fc)\n",
        "  decoder_embedding_matrix = decoder.embedding.variables[0]\n",
        "\n",
        "  # The BeamSearchDecoder object's call() function takes care of everything.\n",
        "  outputs, final_state, sequence_lengths = decoder_instance(decoder_embedding_matrix, start_tokens=start_tokens, end_token=end_token, initial_state=decoder_initial_state)\n",
        "  # outputs is tfa.seq2seq.FinalBeamSearchDecoderOutput object. \n",
        "  # The final beam predictions are stored in outputs.predicted_id\n",
        "  # outputs.beam_search_decoder_output is a tfa.seq2seq.BeamSearchDecoderOutput object which keep tracks of beam_scores and parent_ids while performing a beam decoding step\n",
        "  # final_state = tfa.seq2seq.BeamSearchDecoderState object.\n",
        "  # Sequence Length = [inference_batch_size, beam_width] details the maximum length of the beams that are generated\n",
        "\n",
        "  \n",
        "  # outputs.predicted_id.shape = (inference_batch_size, time_step_outputs, beam_width)\n",
        "  # outputs.beam_search_decoder_output.scores.shape = (inference_batch_size, time_step_outputs, beam_width)\n",
        "  # Convert the shape of outputs and beam_scores to (inference_batch_size, beam_width, time_step_outputs)\n",
        "  final_outputs = tf.transpose(outputs.predicted_ids, perm=(0,2,1))\n",
        "  beam_scores = tf.transpose(outputs.beam_search_decoder_output.scores, perm=(0,2,1))\n",
        "  \n",
        "  return final_outputs.numpy(), beam_scores.numpy()"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g_LvXGvX8X-O"
      },
      "source": [
        "def beam_translate(sentence):\n",
        "  result, beam_scores = beam_evaluate_sentence(sentence)\n",
        "  print(result.shape, beam_scores.shape)\n",
        "  for beam, score in zip(result, beam_scores):\n",
        "    print(beam.shape, score.shape)\n",
        "    output = targ_lang.sequences_to_texts(beam)\n",
        "    output = [a[:a.index('<end>')] for a in output]\n",
        "    beam_score = [a.sum() for a in score]\n",
        "    print('Input: %s' % (sentence))\n",
        "    for i in range(len(output)):\n",
        "      print('{} Predicted translation: {}  {}'.format(i+1, output[i], beam_score[i]))\n"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TODnXBleDzzO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "16770d8d-7fda-4678-f731-2282b48df4ba"
      },
      "source": [
        "beam_translate(u'hace mucho frio aqui.')"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "beam_with * [batch_size, max_length_input, rnn_units] :  3 * [1, 16, 1024]] : (5, 16, 1000)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow_addons/utils/resource_loader.py:103: UserWarning: You are currently using TensorFlow 2.4.1 and trying to load a custom op (custom_ops/seq2seq/_beam_search_ops.so).\n",
            "TensorFlow Addons has compiled its custom ops against TensorFlow 2.2.0, and there are no compatibility guarantees between the two versions. \n",
            "This means that you might get segfaults when loading the custom op, or other kind of low-level errors.\n",
            " If you do, do not file an issue on Github. This is a known limitation.\n",
            "\n",
            "It might help you to fallback to pure Python ops with TF_ADDONS_PY_OPS . To do that, see https://github.com/tensorflow/addons#gpucpu-custom-ops \n",
            "\n",
            "You can also change the TensorFlow version installed on your system. You would need a TensorFlow version equal to or above 2.2.0 and strictly below 2.3.0.\n",
            " Note that nightly versions of TensorFlow, as well as non-pip TensorFlow like `conda install tensorflow` or compiled from source are not supported.\n",
            "\n",
            "The last solution is to find the TensorFlow Addons version that has custom ops compatible with the TensorFlow installed on your system. To do that, refer to the readme: https://github.com/tensorflow/addons\n",
            "  UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow_addons/options.py:47: RuntimeWarning: Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow_addons/seq2seq/beam_search_decoder.py\", line 239, in gather_tree\n",
            "    return _beam_search_so.ops.addons_gather_tree(\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow_addons/utils/resource_loader.py\", line 64, in ops\n",
            "    self._ops = tf.load_op_library(get_path_to_datafile(self.relative_path))\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/load_library.py\", line 57, in load_op_library\n",
            "    lib_handle = py_tf.TF_LoadLibrary(library_filename)\n",
            "tensorflow.python.framework.errors_impl.NotFoundError: /usr/local/lib/python3.7/dist-packages/tensorflow_addons/custom_ops/seq2seq/_beam_search_ops.so: undefined symbol: _ZN10tensorflow8OpKernel11TraceStringEPNS_15OpKernelContextEb\n",
            "\n",
            "\n",
            "The gather_tree C++/CUDA custom op could not be loaded.\n",
            "For this reason, Addons will fallback to an implementation written\n",
            "in Python with public TensorFlow ops. There worst you might experience with\n",
            "this is a moderate slowdown on GPU. There can be multiple\n",
            "reason for this loading error, one of them may be an ABI incompatibility between\n",
            "the TensorFlow installed on your system and the TensorFlow used to compile\n",
            "TensorFlow Addons' custom ops. The stacktrace generated when loading the\n",
            "shared object file was displayed above.\n",
            "\n",
            "If you want this warning to disappear, either make sure the TensorFlow installed\n",
            "is compatible with this version of Addons, or tell TensorFlow Addons to\n",
            "prefer using Python implementations and not custom C++/CUDA ones. You can do that\n",
            "by changing the TF_ADDONS_PY_OPS flag\n",
            "either with the environment variable:\n",
            "```bash\n",
            "TF_ADDONS_PY_OPS=1 python my_script.py\n",
            "```\n",
            "or in your code, after your imports:\n",
            "```python\n",
            "import tensorflow_addons as tfa\n",
            "import ...\n",
            "import ...\n",
            "\n",
            "tfa.options.TF_ADDONS_PY_OPS = True\n",
            "```\n",
            "\n",
            "  warnings.warn(warning_msg, RuntimeWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(1, 5, 2) (1, 5, 2)\n",
            "(5, 2) (5, 2)\n",
            "Input: hace mucho frio aqui.\n",
            "1 Predicted translation:   -16.889036178588867\n",
            "2 Predicted translation: .   -25.37064552307129\n",
            "3 Predicted translation: earache   -25.405670166015625\n",
            "4 Predicted translation: tattoo   -25.410114288330078\n",
            "5 Predicted translation: critic   -25.41189956665039\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_BezQwENFY3L",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1a3ee670-58fa-4534-f792-f10f7db84cc9"
      },
      "source": [
        "beam_translate(u'¿todavia estan en casa?')"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "beam_with * [batch_size, max_length_input, rnn_units] :  3 * [1, 16, 1024]] : (5, 16, 1000)\n",
            "(1, 5, 2) (1, 5, 2)\n",
            "(5, 2) (5, 2)\n",
            "Input: ¿todavia estan en casa?\n",
            "1 Predicted translation:   -16.891246795654297\n",
            "2 Predicted translation: .   -25.37410545349121\n",
            "3 Predicted translation: earache   -25.403606414794922\n",
            "4 Predicted translation: milan   -25.411874771118164\n",
            "5 Predicted translation: critic   -25.412967681884766\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "si68rj5homcO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6141ee87-10d2-4641-d65d-938b8d6d8a23"
      },
      "source": [
        "print(1)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sfv60Gxq6aPZ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}