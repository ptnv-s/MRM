{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "su00atkqqzjZ",
    "outputId": "ada55cad-f86a-4919-bc39-a746d0b0b501"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -q pyyaml h5py  # Required to save models in HDF5 format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-IF3LjvXqdJi"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import unicodedata\n",
    "import string\n",
    "import numpy as np\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "#from google.colab import drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 122
    },
    "colab_type": "code",
    "id": "cUoGvxNddFHh",
    "outputId": "7e1b86b4-0462-4653-fb0c-35b3719f760d"
   },
   "outputs": [],
   "source": [
    "def Convert(string):\n",
    "    li = list(string.split(\" \"))\n",
    "    return li"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def listToString(s): \n",
    "    \n",
    "    # initialize an empty string\n",
    "    str1 = ' ' \n",
    "    \n",
    "    # return string  \n",
    "    return (str1.join(s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "44g54wKWqdJp",
    "outputId": "112f25af-1c1d-4e1a-9869-e5ee602d5366"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.4.1\n"
     ]
    }
   ],
   "source": [
    "keras = tf.keras\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 255
    },
    "colab_type": "code",
    "id": "DEed-KleNdUK",
    "outputId": "4a4373cb-9ab9-4fc5-b654-b5bb8b6cbd65"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2021-03-28 04:19:35--  https://www.manythings.org/anki/fra-eng.zip\n",
      "Resolving www.manythings.org... 172.67.173.198, 104.21.55.222, 2606:4700:3036::ac43:adc6, ...\n",
      "Connecting to www.manythings.org|172.67.173.198|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 6281268 (6.0M) [application/zip]\n",
      "Saving to: ‘fra-eng.zip.4’\n",
      "\n",
      "fra-eng.zip.4       100%[===================>]   5.99M  1.22MB/s    in 5.6s    \n",
      "\n",
      "2021-03-28 04:19:42 (1.07 MB/s) - ‘fra-eng.zip.4’ saved [6281268/6281268]\n",
      "\n",
      "Archive:  fra-eng.zip\n",
      "replace _about.txt? [y]es, [n]o, [A]ll, [N]one, [r]ename: ^C\n"
     ]
    }
   ],
   "source": [
    "!wget https://www.manythings.org/anki/fra-eng.zip\n",
    "!unzip  fra-eng.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UHgfCZXVqdJu"
   },
   "outputs": [],
   "source": [
    "SOS_token = 0\n",
    "EOS_token = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KSK6zPRUqdJz"
   },
   "outputs": [],
   "source": [
    "class Lang(object):\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.word2int = {}\n",
    "        self.word2count = {}\n",
    "        self.int2word = {0 : \"SOS\", 1 : \"EOS\"}\n",
    "        self.n_words = 2\n",
    "        \n",
    "    def addWord(self, word):\n",
    "        if word not in self.word2int:\n",
    "            self.word2int[word] = self.n_words\n",
    "            self.word2count[word] = 1\n",
    "            self.int2word[self.n_words] = word\n",
    "            self.n_words += 1\n",
    "            \n",
    "        else:\n",
    "            self.word2count[word] += 1\n",
    "    \n",
    "    def addSentence(self, sentence):\n",
    "        for word in sentence.split(\" \"):\n",
    "            self.addWord(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8UujikttqdJ7"
   },
   "outputs": [],
   "source": [
    "def unicodeToAscii(s):\n",
    "    return \"\".join(c for c in unicodedata.normalize(\"NFD\", s) \\\n",
    "                   if unicodedata.category(c) != \"Mn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Sb0sLusAqdKA"
   },
   "outputs": [],
   "source": [
    "def normalizeString(s):\n",
    "    s = unicodeToAscii(s.lower().strip())\n",
    "    \n",
    "    s = re.sub(r\"([!.?])\", r\" \\1\", s)\n",
    "    s = re.sub(r\"[^a-zA-Z?.!]+\", \" \", s)\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mbvFe0iqqdKF"
   },
   "outputs": [],
   "source": [
    "def load_dataset():\n",
    "    with open(\"fra.txt\",'r') as f:\n",
    "        lines = f.readlines()\n",
    "    \n",
    "    pairs = [[normalizeString(pair) for pair in \n",
    "              line.strip().split('\\t')] for line in lines]\n",
    "    return pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "26fM5LRUqdKJ"
   },
   "outputs": [],
   "source": [
    "pairs = load_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jnmGqtDOqdKN"
   },
   "outputs": [],
   "source": [
    "MAX_LENGTH = 10\n",
    "def sentencetoIndexes(sentence, lang):\n",
    "    indexes = [lang.word2int[word] for word in sentence.split()]\n",
    "    indexes.append(EOS_token)\n",
    "    return indexes\n",
    "\n",
    "def filterPair(p):\n",
    "    return len(p[0].split()) < MAX_LENGTH and \\\n",
    "len(p[1].split()) < MAX_LENGTH\n",
    "\n",
    "def filterPairs(pairs):\n",
    "    return [pair for pair in pairs if filterPair(pair)]\n",
    "\n",
    "pairs = filterPairs(pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "GQbB37mcsHb_",
    "outputId": "fad2916c-973b-49e3-9543-ca0dbefa43ab"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cc by . france attribution tatoeba .org cm wittydev '"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pairs[0][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JlAGPZShqdKT"
   },
   "outputs": [],
   "source": [
    "def build_lang(lang1, lang2, max_length=10):\n",
    "    input_lang = Lang(lang1)\n",
    "    output_lang = Lang(lang2)\n",
    "    input_seq = []\n",
    "    output_seq = []\n",
    "    \n",
    "    for pair in pairs:\n",
    "        input_lang.addSentence(pair[1])\n",
    "        output_lang.addSentence(pair[0])\n",
    "    for pair in pairs:\n",
    "        input_seq.append(sentencetoIndexes(pair[1], input_lang))\n",
    "        output_seq.append(sentencetoIndexes(pair[0], output_lang))\n",
    "    return keras.preprocessing.sequence.pad_sequences(input_seq, maxlen=max_length, padding='post',\n",
    "                                                      truncating='post'), \\\n",
    "keras.preprocessing.sequence.pad_sequences(output_seq, padding='post', truncating='post'), input_lang, output_lang"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Q9MAxjU-qdKY"
   },
   "outputs": [],
   "source": [
    "input_tensor, output_tensor, input_lang, output_lang = build_lang('fr', 'en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "YZ8Pcm1Ls8Cc",
    "outputId": "2937839a-ccbd-4eba-da49-85f03e91bdbc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'fr'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_lang.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qii6d6iKqdKc"
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 128\n",
    "BUFFER_SIZE = len(input_tensor)\n",
    "dataset = tf.data.Dataset.from_tensor_slices((input_tensor, output_tensor)).shuffle(BUFFER_SIZE)\n",
    "dataset = dataset.batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "41nSXuflqdKh"
   },
   "outputs": [],
   "source": [
    "class Encoder(keras.models.Model):\n",
    "    def __init__(self, vocab_size, num_hidden=256, num_embedding=256, batch_size=128):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.batch_size = batch_size\n",
    "        self.num_hidden = num_hidden\n",
    "        self.num_embedding = num_embedding\n",
    "        self.embedding = keras.layers.Embedding(vocab_size, num_embedding)\n",
    "        self.gru = keras.layers.GRU(num_hidden, return_sequences=True,\n",
    "                                    recurrent_initializer='glorot_uniform',\n",
    "                                   return_state=True)\n",
    "        \n",
    "    def call(self, x, hidden):\n",
    "        embedded = self.embedding(x)\n",
    "        rnn_out, hidden = self.gru(embedded, initial_state=hidden)\n",
    "        return rnn_out, hidden\n",
    "    def init_hidden(self):\n",
    "        return tf.zeros(shape=(self.batch_size, self.num_hidden))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7qm8zLgoqdKk"
   },
   "outputs": [],
   "source": [
    "inputs, outputs = next(iter(dataset))\n",
    "hidden = tf.zeros((128, 256))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "x5AHvxMiqdKo"
   },
   "outputs": [],
   "source": [
    "encoder = Encoder(input_lang.n_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bCF-S8fBqdKs"
   },
   "outputs": [],
   "source": [
    "e_outputs, e_hidden = encoder(inputs, hidden)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 255
    },
    "colab_type": "code",
    "id": "AqGefguVqdKv",
    "outputId": "0b8b976b-6267-40b2-be27-f663781cf1f9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(128, 256), dtype=float32, numpy=\n",
       "array([[ 0.00120121,  0.00040375,  0.00781761, ...,  0.01604841,\n",
       "         0.00540511, -0.02816603],\n",
       "       [ 0.00729156,  0.00092345,  0.01161359, ...,  0.0379127 ,\n",
       "         0.00293805, -0.0326785 ],\n",
       "       [ 0.00635105,  0.00290918,  0.01400031, ...,  0.0285332 ,\n",
       "         0.00682477, -0.03156468],\n",
       "       ...,\n",
       "       [ 0.00396224,  0.00047232,  0.01347383, ...,  0.03284305,\n",
       "         0.00264421, -0.03273234],\n",
       "       [ 0.00484819,  0.00595837,  0.00248137, ..., -0.00217395,\n",
       "         0.01141609, -0.01265813],\n",
       "       [ 0.00077437, -0.00138516,  0.00955012, ...,  0.01716059,\n",
       "         0.00580018, -0.0205926 ]], dtype=float32)>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e_hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_bJHJsq1qdK6"
   },
   "outputs": [],
   "source": [
    "class BahdanauAttention(keras.models.Model):\n",
    "    def __init__(self, units):\n",
    "        super(BahdanauAttention, self).__init__()\n",
    "    \n",
    "        self.W1 = keras.layers.Dense(units)\n",
    "        self.W2 = keras.layers.Dense(units)\n",
    "        self.V = keras.layers.Dense(1)\n",
    "        \n",
    "    def call(self, encoder_out, hidden):\n",
    "        #shape of encoder_out : batch_size, seq_length, hidden_dim \n",
    "        #shape of encoder_hidden : batch_size, hidden_dim \n",
    "        \n",
    "        hidden = tf.expand_dims(hidden, axis=1) #out:\n",
    "        \n",
    "        score = self.V(tf.nn.tanh(self.W1(encoder_out) + \\\n",
    "                                  self.W2(hidden))) \n",
    "        \n",
    "        attn_weights = tf.nn.softmax(score, axis=1)\n",
    "        \n",
    "        context =  attn_weights * encoder_out \n",
    "        context = tf.reduce_sum(context, axis=1)\n",
    "        return context, attn_weights\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4gRC60cCqdK-"
   },
   "outputs": [],
   "source": [
    "attn = BahdanauAttention(256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OHU6rIRzqdLC"
   },
   "outputs": [],
   "source": [
    "context, attn_weights = attn(e_outputs, e_hidden)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "G2XacZYkqdLK",
    "outputId": "2f5997bb-f3bd-4679-e12a-70f2181bfbe6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([128, 10, 1])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attn_weights.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WsLImrCwqdLT"
   },
   "outputs": [],
   "source": [
    "class Decoder(keras.models.Model):\n",
    "    def __init__(self, vocab_size, dec_dim=256, embedding_dim=256):\n",
    "        super(Decoder, self).__init__()\n",
    "        \n",
    "        self.attn = BahdanauAttention(dec_dim)\n",
    "        self.embedding = keras.layers.Embedding(vocab_size, embedding_dim)\n",
    "        self.gru = keras.layers.GRU(dec_dim, recurrent_initializer='glorot_uniform',\n",
    "                                   return_sequences=True, return_state=True)\n",
    "        self.fc = keras.layers.Dense(vocab_size)\n",
    "        \n",
    "    def call(self, x, enc_hidden, enc_out):\n",
    "        x = self.embedding(x)\n",
    "        context, attn_weights = self.attn(enc_out, enc_hidden)\n",
    "        x = tf.concat((tf.expand_dims(context, 1), x), -1)\n",
    "        r_out, hidden = self.gru(x, initial_state=enc_hidden)\n",
    "        out = tf.reshape(r_out,shape=(-1, r_out.shape[2]))\n",
    "        return self.fc(out), hidden, attn_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ItYHAqWJqdLY"
   },
   "outputs": [],
   "source": [
    "decoder = Decoder(output_lang.n_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XnhNtfb9qdLe"
   },
   "outputs": [],
   "source": [
    "input_tensor, output_tensor = next(iter(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "G7Y7QsykqdLi"
   },
   "outputs": [],
   "source": [
    "x = np.expand_dims(output_tensor[:,1], -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1DE7fnvAqdLp"
   },
   "outputs": [],
   "source": [
    "def loss_fn(real, pred):\n",
    "    criterion = keras.losses.SparseCategoricalCrossentropy(from_logits=True,\n",
    "                                                           reduction='none')\n",
    "    mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
    "    _loss = criterion(real, pred)\n",
    "    mask = tf.cast(mask, dtype=_loss.dtype)\n",
    "    _loss *= mask\n",
    "    return tf.reduce_mean(_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MMc7zD6WqdLt"
   },
   "outputs": [],
   "source": [
    "optimizer = tf.optimizers.Adam()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hiAmynEsqdLw"
   },
   "outputs": [],
   "source": [
    "def train_step(input_tensor, target_tensor, enc_hidden):\n",
    "    loss = 0.0\n",
    "    with tf.GradientTape() as tape:\n",
    "    \n",
    "        batch_size = input_tensor.shape[0]\n",
    "        enc_output, enc_hidden = encoder(input_tensor, enc_hidden)\n",
    "\n",
    "        SOS_tensor = np.array([SOS_token])\n",
    "        dec_input = tf.squeeze(tf.expand_dims([SOS_tensor]*batch_size, 1), -1)\n",
    "        dec_hidden = enc_hidden\n",
    "\n",
    "        for tx in range(target_tensor.shape[1]-1):\n",
    "          \n",
    "            dec_out, dec_hidden, _ = decoder(dec_input, dec_hidden,\n",
    "                                            enc_output)\n",
    "            loss += loss_fn(target_tensor[:, tx], dec_out)\n",
    "            dec_input = tf.expand_dims(target_tensor[:, tx], 1)\n",
    "\n",
    "    batch_loss = loss / target_tensor.shape[1]\n",
    "    t_variables = encoder.trainable_variables + decoder.trainable_variables\n",
    "    gradients = tape.gradient(loss, t_variables)\n",
    "    optimizer.apply_gradients(zip(gradients, t_variables))\n",
    "    return batch_loss\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "6kj6diJMqdL0",
    "outputId": "97f30803-0152-4e1a-dee9-92d68251ec4e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(6.6888223, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "hidden = tf.zeros(shape=(128, 256))\n",
    "loss = train_step(input_tensor, output_tensor, hidden)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Lk_OG391qdL5"
   },
   "outputs": [],
   "source": [
    "def checkpoint(model, name=None):\n",
    "    if name is not None:\n",
    "        model.save_weights('{}.h5'.format(name))\n",
    "    else:\n",
    "        raise NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rZEbkwx9qdL-"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 1 batch_loss: 6.7541\n",
      "Epochs: 1 batch_loss: 6.2169\n",
      "Epochs: 1 batch_loss: 4.4412\n",
      "Epochs: 1 batch_loss: 3.9101\n",
      "Epochs: 1 batch_loss: 3.8257\n",
      "Epochs: 1 batch_loss: 3.9369\n",
      "Epochs: 1 batch_loss: 3.8754\n",
      "Epochs: 1 batch_loss: 3.8226\n",
      "Epochs: 1 batch_loss: 3.7262\n",
      "Epochs: 1 batch_loss: 3.8326\n",
      "Epochs: 1 batch_loss: 3.6739\n",
      "Epochs: 1 batch_loss: 3.7136\n",
      "Epochs: 1 batch_loss: 3.7685\n",
      "Epochs: 1 batch_loss: 3.7749\n",
      "Epochs: 1 batch_loss: 3.7368\n",
      "Epochs: 1 batch_loss: 3.6167\n",
      "Epochs: 1 batch_loss: 3.6063\n",
      "Epochs: 1 batch_loss: 3.7400\n",
      "Epochs: 1 batch_loss: 3.5559\n",
      "Epochs: 1 batch_loss: 3.5124\n",
      "Epochs: 1 batch_loss: 3.6554\n",
      "Epochs: 1 batch_loss: 3.5912\n",
      "Epochs: 1 batch_loss: 3.4930\n",
      "Epochs: 1 batch_loss: 3.5730\n",
      "Epochs: 1 batch_loss: 3.6357\n",
      "Epochs: 1 batch_loss: 3.4722\n",
      "Epochs: 1 batch_loss: 3.5131\n",
      "Epochs: 1 batch_loss: 3.4824\n",
      "Epochs: 1 batch_loss: 3.4212\n",
      "Epochs: 1 batch_loss: 3.3980\n",
      "Epochs: 1 batch_loss: 3.4984\n",
      "Epochs: 1 batch_loss: 3.5021\n",
      "Epochs: 1 batch_loss: 3.4398\n",
      "Epochs: 1 batch_loss: 3.4936\n",
      "Epochs: 1 batch_loss: 3.4438\n",
      "Epochs: 1 batch_loss: 3.5078\n",
      "Epochs: 1 batch_loss: 3.3735\n",
      "Epochs: 1 batch_loss: 3.4866\n",
      "Epochs: 1 batch_loss: 3.4100\n",
      "Epochs: 1 batch_loss: 3.3474\n",
      "Epochs: 1 batch_loss: 3.2737\n",
      "Epochs: 1 batch_loss: 3.2327\n",
      "Epochs: 1 batch_loss: 3.3931\n",
      "Epochs: 1 batch_loss: 3.2375\n",
      "Epochs: 1 batch_loss: 3.2973\n",
      "Epochs: 1 batch_loss: 3.3246\n",
      "Epochs: 1 batch_loss: 3.3444\n",
      "Epochs: 1 batch_loss: 3.3552\n",
      "Epochs: 1 batch_loss: 3.2679\n",
      "Epochs: 1 batch_loss: 3.3553\n",
      "Epochs: 1 batch_loss: 3.2369\n",
      "Epochs: 1 batch_loss: 3.2521\n",
      "Epochs: 1 batch_loss: 3.4088\n",
      "Epochs: 1 batch_loss: 3.1408\n",
      "Epochs: 1 batch_loss: 3.2115\n",
      "Epochs: 1 batch_loss: 3.2094\n",
      "Epochs: 1 batch_loss: 3.3116\n",
      "Epochs: 1 batch_loss: 3.1376\n",
      "Epochs: 1 batch_loss: 3.2540\n",
      "Epochs: 1 batch_loss: 3.1899\n",
      "Epochs: 1 batch_loss: 3.2830\n",
      "Epochs: 1 batch_loss: 3.1881\n",
      "Epochs: 1 batch_loss: 3.2139\n",
      "Epochs: 1 batch_loss: 3.3757\n",
      "Epochs: 1 batch_loss: 3.2674\n",
      "Epochs: 1 batch_loss: 3.2477\n",
      "Epochs: 1 batch_loss: 3.2539\n",
      "Epochs: 1 batch_loss: 3.1652\n",
      "Epochs: 1 batch_loss: 3.4117\n",
      "Epochs: 1 batch_loss: 3.1886\n",
      "Epochs: 1 batch_loss: 3.1761\n",
      "Epochs: 1 batch_loss: 3.1840\n",
      "Epochs: 1 batch_loss: 3.2498\n",
      "Epochs: 1 batch_loss: 3.4683\n",
      "Epochs: 1 batch_loss: 3.0773\n",
      "Epochs: 1 batch_loss: 3.2650\n",
      "Epochs: 1 batch_loss: 3.1947\n",
      "Epochs: 1 batch_loss: 3.1016\n",
      "Epochs: 1 batch_loss: 3.1293\n",
      "Epochs: 1 batch_loss: 3.2645\n",
      "Epochs: 1 batch_loss: 3.0891\n",
      "Epochs: 1 batch_loss: 3.3753\n",
      "Epochs: 1 batch_loss: 3.1772\n",
      "Epochs: 1 batch_loss: 3.2804\n",
      "Epochs: 1 batch_loss: 3.1420\n",
      "Epochs: 1 batch_loss: 3.1940\n",
      "Epochs: 1 batch_loss: 3.2303\n",
      "Epochs: 1 batch_loss: 3.0517\n",
      "Epochs: 1 batch_loss: 2.9942\n",
      "Epochs: 1 batch_loss: 3.3058\n",
      "Epochs: 1 batch_loss: 3.1997\n",
      "Epochs: 1 batch_loss: 3.2856\n",
      "Epochs: 1 batch_loss: 3.0342\n",
      "Epochs: 1 batch_loss: 3.1659\n",
      "Epochs: 1 batch_loss: 3.2405\n",
      "Epochs: 1 batch_loss: 3.0202\n",
      "Epochs: 1 batch_loss: 3.1368\n",
      "Epochs: 1 batch_loss: 3.0543\n",
      "Epochs: 1 batch_loss: 3.1971\n",
      "Epochs: 1 batch_loss: 3.1660\n",
      "Epochs: 1 batch_loss: 3.1079\n",
      "Epochs: 1 batch_loss: 3.0494\n",
      "Epochs: 1 batch_loss: 3.0108\n",
      "Epochs: 1 batch_loss: 3.0019\n",
      "Epochs: 1 batch_loss: 3.1412\n",
      "Epochs: 1 batch_loss: 3.2373\n",
      "Epochs: 1 batch_loss: 3.1323\n",
      "Epochs: 1 batch_loss: 3.0743\n",
      "Epochs: 1 batch_loss: 3.1670\n",
      "Epochs: 1 batch_loss: 3.1027\n",
      "Epochs: 1 batch_loss: 3.1087\n",
      "Epochs: 1 batch_loss: 3.1229\n",
      "Epochs: 1 batch_loss: 3.0117\n",
      "Epochs: 1 batch_loss: 2.9855\n",
      "Epochs: 1 batch_loss: 3.0001\n",
      "Epochs: 1 batch_loss: 3.0886\n",
      "Epochs: 1 batch_loss: 3.1393\n",
      "Epochs: 1 batch_loss: 3.0957\n",
      "Epochs: 1 batch_loss: 3.1397\n",
      "Epochs: 1 batch_loss: 3.0181\n",
      "Epochs: 1 batch_loss: 3.1854\n",
      "Epochs: 1 batch_loss: 3.0846\n",
      "Epochs: 1 batch_loss: 3.1433\n",
      "Epochs: 1 batch_loss: 3.1632\n",
      "Epochs: 1 batch_loss: 3.0631\n",
      "Epochs: 1 batch_loss: 3.1151\n",
      "Epochs: 1 batch_loss: 2.9791\n",
      "Epochs: 1 batch_loss: 3.0885\n",
      "Epochs: 1 batch_loss: 3.0423\n",
      "Epochs: 1 batch_loss: 2.9624\n",
      "Epochs: 1 batch_loss: 3.1085\n",
      "Epochs: 1 batch_loss: 2.9314\n",
      "Epochs: 1 batch_loss: 2.9670\n",
      "Epochs: 1 batch_loss: 2.9375\n",
      "Epochs: 1 batch_loss: 3.1389\n",
      "Epochs: 1 batch_loss: 2.9051\n",
      "Epochs: 1 batch_loss: 2.9528\n",
      "Epochs: 1 batch_loss: 2.9783\n",
      "Epochs: 1 batch_loss: 2.8250\n",
      "Epochs: 1 batch_loss: 2.8745\n",
      "Epochs: 1 batch_loss: 3.0145\n",
      "Epochs: 1 batch_loss: 2.9637\n",
      "Epochs: 1 batch_loss: 3.0283\n",
      "Epochs: 1 batch_loss: 2.7403\n",
      "Epochs: 1 batch_loss: 2.9467\n",
      "Epochs: 1 batch_loss: 3.1725\n",
      "Epochs: 1 batch_loss: 2.9618\n",
      "Epochs: 1 batch_loss: 2.8883\n",
      "Epochs: 1 batch_loss: 3.0002\n",
      "Epochs: 1 batch_loss: 3.0171\n",
      "Epochs: 1 batch_loss: 2.9615\n",
      "Epochs: 1 batch_loss: 3.0491\n",
      "Epochs: 1 batch_loss: 2.9817\n",
      "Epochs: 1 batch_loss: 2.9996\n",
      "Epochs: 1 batch_loss: 2.9566\n",
      "Epochs: 1 batch_loss: 3.0272\n",
      "Epochs: 1 batch_loss: 2.9139\n",
      "Epochs: 1 batch_loss: 2.9163\n",
      "Epochs: 1 batch_loss: 2.8974\n",
      "Epochs: 1 batch_loss: 2.9597\n",
      "Epochs: 1 batch_loss: 2.7885\n",
      "Epochs: 1 batch_loss: 2.9662\n",
      "Epochs: 1 batch_loss: 2.8743\n",
      "Epochs: 1 batch_loss: 2.8049\n",
      "Epochs: 1 batch_loss: 2.9587\n",
      "Epochs: 1 batch_loss: 2.9258\n",
      "Epochs: 1 batch_loss: 2.8722\n",
      "Epochs: 1 batch_loss: 2.8455\n",
      "Epochs: 1 batch_loss: 2.9992\n",
      "Epochs: 1 batch_loss: 2.8660\n",
      "Epochs: 1 batch_loss: 2.9697\n",
      "Epochs: 1 batch_loss: 2.8623\n",
      "Epochs: 1 batch_loss: 2.9574\n",
      "Epochs: 1 batch_loss: 2.7927\n",
      "Epochs: 1 batch_loss: 2.9473\n",
      "Epochs: 1 batch_loss: 2.9588\n",
      "Epochs: 1 batch_loss: 2.9471\n",
      "Epochs: 1 batch_loss: 2.9633\n",
      "Epochs: 1 batch_loss: 2.7480\n",
      "Epochs: 1 batch_loss: 3.0135\n",
      "Epochs: 1 batch_loss: 2.9511\n",
      "Epochs: 1 batch_loss: 2.9290\n",
      "Epochs: 1 batch_loss: 2.8419\n",
      "Epochs: 1 batch_loss: 2.9152\n",
      "Epochs: 1 batch_loss: 2.9407\n",
      "Epochs: 1 batch_loss: 2.7894\n",
      "Epochs: 1 batch_loss: 2.8240\n",
      "Epochs: 1 batch_loss: 2.8609\n",
      "Epochs: 1 batch_loss: 2.7853\n",
      "Epochs: 1 batch_loss: 2.7208\n",
      "Epochs: 1 batch_loss: 2.7256\n",
      "Epochs: 1 batch_loss: 2.8821\n",
      "Epochs: 1 batch_loss: 2.6934\n",
      "Epochs: 1 batch_loss: 2.7148\n",
      "Epochs: 1 batch_loss: 2.7610\n",
      "Epochs: 1 batch_loss: 2.7813\n",
      "Epochs: 1 batch_loss: 2.8377\n",
      "Epochs: 1 batch_loss: 2.8606\n",
      "Epochs: 1 batch_loss: 2.8066\n",
      "Epochs: 1 batch_loss: 2.7801\n",
      "Epochs: 1 batch_loss: 2.8996\n",
      "Epochs: 1 batch_loss: 2.6408\n",
      "Epochs: 1 batch_loss: 2.8633\n",
      "Epochs: 1 batch_loss: 2.5865\n",
      "Epochs: 1 batch_loss: 2.5992\n",
      "Epochs: 1 batch_loss: 2.8988\n",
      "Epochs: 1 batch_loss: 2.7144\n",
      "Epochs: 2 batch_loss: 2.7135\n",
      "Epochs: 2 batch_loss: 2.6584\n",
      "Epochs: 2 batch_loss: 2.6301\n",
      "Epochs: 2 batch_loss: 2.6769\n",
      "Epochs: 2 batch_loss: 2.5465\n",
      "Epochs: 2 batch_loss: 2.6966\n",
      "Epochs: 2 batch_loss: 2.5952\n",
      "Epochs: 2 batch_loss: 2.7647\n",
      "Epochs: 2 batch_loss: 2.8225\n",
      "Epochs: 2 batch_loss: 2.6559\n",
      "Epochs: 2 batch_loss: 2.6774\n",
      "Epochs: 2 batch_loss: 2.6574\n",
      "Epochs: 2 batch_loss: 2.7206\n",
      "Epochs: 2 batch_loss: 2.6641\n",
      "Epochs: 2 batch_loss: 2.5856\n",
      "Epochs: 2 batch_loss: 2.6100\n",
      "Epochs: 2 batch_loss: 2.5386\n",
      "Epochs: 2 batch_loss: 2.5710\n",
      "Epochs: 2 batch_loss: 2.6427\n",
      "Epochs: 2 batch_loss: 2.5402\n",
      "Epochs: 2 batch_loss: 2.5244\n",
      "Epochs: 2 batch_loss: 2.5571\n",
      "Epochs: 2 batch_loss: 2.4335\n",
      "Epochs: 2 batch_loss: 2.6666\n",
      "Epochs: 2 batch_loss: 2.5205\n",
      "Epochs: 2 batch_loss: 2.5064\n",
      "Epochs: 2 batch_loss: 2.4320\n",
      "Epochs: 2 batch_loss: 2.5467\n",
      "Epochs: 2 batch_loss: 2.6674\n",
      "Epochs: 2 batch_loss: 2.5224\n",
      "Epochs: 2 batch_loss: 2.4972\n",
      "Epochs: 2 batch_loss: 2.4094\n",
      "Epochs: 2 batch_loss: 2.4999\n",
      "Epochs: 2 batch_loss: 2.5607\n",
      "Epochs: 2 batch_loss: 2.5012\n",
      "Epochs: 2 batch_loss: 2.4299\n",
      "Epochs: 2 batch_loss: 2.4259\n",
      "Epochs: 2 batch_loss: 2.4719\n",
      "Epochs: 2 batch_loss: 2.5749\n",
      "Epochs: 2 batch_loss: 2.4094\n",
      "Epochs: 2 batch_loss: 2.5821\n",
      "Epochs: 2 batch_loss: 2.3736\n",
      "Epochs: 2 batch_loss: 2.4004\n",
      "Epochs: 2 batch_loss: 2.4773\n",
      "Epochs: 2 batch_loss: 2.4516\n",
      "Epochs: 2 batch_loss: 2.3593\n",
      "Epochs: 2 batch_loss: 2.3352\n",
      "Epochs: 2 batch_loss: 2.4934\n",
      "Epochs: 2 batch_loss: 2.2566\n",
      "Epochs: 2 batch_loss: 2.4273\n",
      "Epochs: 2 batch_loss: 2.3791\n",
      "Epochs: 2 batch_loss: 2.4968\n",
      "Epochs: 2 batch_loss: 2.4010\n",
      "Epochs: 2 batch_loss: 2.2659\n",
      "Epochs: 2 batch_loss: 2.4857\n",
      "Epochs: 2 batch_loss: 2.4490\n",
      "Epochs: 2 batch_loss: 2.3710\n",
      "Epochs: 2 batch_loss: 2.4104\n",
      "Epochs: 2 batch_loss: 2.3568\n",
      "Epochs: 2 batch_loss: 2.3539\n",
      "Epochs: 2 batch_loss: 2.4189\n",
      "Epochs: 2 batch_loss: 2.2969\n",
      "Epochs: 2 batch_loss: 2.3000\n",
      "Epochs: 2 batch_loss: 2.2954\n",
      "Epochs: 2 batch_loss: 2.2685\n",
      "Epochs: 2 batch_loss: 2.4035\n",
      "Epochs: 2 batch_loss: 2.2644\n",
      "Epochs: 2 batch_loss: 2.3615\n",
      "Epochs: 2 batch_loss: 2.4055\n",
      "Epochs: 2 batch_loss: 2.3201\n",
      "Epochs: 2 batch_loss: 2.1765\n",
      "Epochs: 2 batch_loss: 2.2292\n",
      "Epochs: 2 batch_loss: 2.3305\n",
      "Epochs: 2 batch_loss: 2.3801\n",
      "Epochs: 2 batch_loss: 2.2631\n",
      "Epochs: 2 batch_loss: 2.2305\n",
      "Epochs: 2 batch_loss: 2.2998\n",
      "Epochs: 2 batch_loss: 2.2636\n",
      "Epochs: 2 batch_loss: 2.3316\n",
      "Epochs: 2 batch_loss: 2.1878\n",
      "Epochs: 2 batch_loss: 2.2669\n",
      "Epochs: 2 batch_loss: 2.3309\n",
      "Epochs: 2 batch_loss: 2.3007\n",
      "Epochs: 2 batch_loss: 2.1478\n",
      "Epochs: 2 batch_loss: 2.1325\n",
      "Epochs: 2 batch_loss: 2.3287\n",
      "Epochs: 2 batch_loss: 2.2186\n",
      "Epochs: 2 batch_loss: 2.0859\n",
      "Epochs: 2 batch_loss: 2.2838\n",
      "Epochs: 2 batch_loss: 2.2111\n",
      "Epochs: 2 batch_loss: 2.4333\n",
      "Epochs: 2 batch_loss: 2.1365\n",
      "Epochs: 2 batch_loss: 2.0984\n",
      "Epochs: 2 batch_loss: 2.3027\n",
      "Epochs: 2 batch_loss: 2.1200\n",
      "Epochs: 2 batch_loss: 2.0849\n",
      "Epochs: 2 batch_loss: 2.1640\n",
      "Epochs: 2 batch_loss: 2.0813\n",
      "Epochs: 2 batch_loss: 2.2064\n",
      "Epochs: 2 batch_loss: 2.0979\n",
      "Epochs: 2 batch_loss: 2.2336\n",
      "Epochs: 2 batch_loss: 2.2840\n",
      "Epochs: 2 batch_loss: 2.1177\n",
      "Epochs: 2 batch_loss: 2.0699\n",
      "Epochs: 2 batch_loss: 2.0984\n",
      "Epochs: 2 batch_loss: 2.0466\n",
      "Epochs: 2 batch_loss: 2.0541\n",
      "Epochs: 2 batch_loss: 2.1818\n",
      "Epochs: 2 batch_loss: 2.0316\n",
      "Epochs: 2 batch_loss: 2.0797\n",
      "Epochs: 2 batch_loss: 1.9678\n",
      "Epochs: 2 batch_loss: 2.0506\n",
      "Epochs: 2 batch_loss: 2.1582\n",
      "Epochs: 2 batch_loss: 2.0585\n",
      "Epochs: 2 batch_loss: 2.1125\n",
      "Epochs: 2 batch_loss: 2.0352\n",
      "Epochs: 2 batch_loss: 2.0844\n",
      "Epochs: 2 batch_loss: 2.1047\n",
      "Epochs: 2 batch_loss: 1.9350\n",
      "Epochs: 2 batch_loss: 2.1473\n",
      "Epochs: 2 batch_loss: 2.0768\n",
      "Epochs: 2 batch_loss: 2.0633\n",
      "Epochs: 2 batch_loss: 2.0240\n",
      "Epochs: 2 batch_loss: 2.1034\n",
      "Epochs: 2 batch_loss: 2.0327\n",
      "Epochs: 2 batch_loss: 2.0939\n",
      "Epochs: 2 batch_loss: 2.0337\n",
      "Epochs: 2 batch_loss: 2.0021\n",
      "Epochs: 2 batch_loss: 1.9874\n",
      "Epochs: 2 batch_loss: 1.9448\n",
      "Epochs: 2 batch_loss: 2.0228\n",
      "Epochs: 2 batch_loss: 2.1373\n",
      "Epochs: 2 batch_loss: 1.9392\n",
      "Epochs: 2 batch_loss: 1.9393\n",
      "Epochs: 2 batch_loss: 2.0758\n",
      "Epochs: 2 batch_loss: 1.9920\n",
      "Epochs: 2 batch_loss: 2.0249\n",
      "Epochs: 2 batch_loss: 1.9830\n",
      "Epochs: 2 batch_loss: 1.8743\n",
      "Epochs: 2 batch_loss: 1.8700\n",
      "Epochs: 2 batch_loss: 1.9572\n",
      "Epochs: 2 batch_loss: 1.9351\n",
      "Epochs: 2 batch_loss: 2.0024\n",
      "Epochs: 2 batch_loss: 1.8907\n",
      "Epochs: 2 batch_loss: 1.9830\n",
      "Epochs: 2 batch_loss: 1.9286\n",
      "Epochs: 2 batch_loss: 1.8997\n",
      "Epochs: 2 batch_loss: 1.9655\n",
      "Epochs: 2 batch_loss: 1.8798\n",
      "Epochs: 2 batch_loss: 1.9283\n",
      "Epochs: 2 batch_loss: 1.9402\n",
      "Epochs: 2 batch_loss: 1.8615\n",
      "Epochs: 2 batch_loss: 1.8924\n",
      "Epochs: 2 batch_loss: 1.8673\n",
      "Epochs: 2 batch_loss: 1.8364\n",
      "Epochs: 2 batch_loss: 1.9360\n",
      "Epochs: 2 batch_loss: 1.8735\n",
      "Epochs: 2 batch_loss: 1.8480\n",
      "Epochs: 2 batch_loss: 1.7540\n",
      "Epochs: 2 batch_loss: 1.7850\n",
      "Epochs: 2 batch_loss: 1.8251\n",
      "Epochs: 2 batch_loss: 1.7519\n",
      "Epochs: 2 batch_loss: 1.8937\n",
      "Epochs: 2 batch_loss: 1.8547\n",
      "Epochs: 2 batch_loss: 1.9427\n",
      "Epochs: 2 batch_loss: 1.7173\n",
      "Epochs: 2 batch_loss: 1.7586\n",
      "Epochs: 2 batch_loss: 1.7479\n",
      "Epochs: 2 batch_loss: 1.7778\n",
      "Epochs: 2 batch_loss: 1.7768\n",
      "Epochs: 2 batch_loss: 1.8455\n",
      "Epochs: 2 batch_loss: 1.8442\n",
      "Epochs: 2 batch_loss: 1.9356\n",
      "Epochs: 2 batch_loss: 1.8142\n",
      "Epochs: 2 batch_loss: 1.6754\n",
      "Epochs: 2 batch_loss: 1.8338\n",
      "Epochs: 2 batch_loss: 1.7726\n",
      "Epochs: 2 batch_loss: 1.8709\n",
      "Epochs: 2 batch_loss: 1.7130\n",
      "Epochs: 2 batch_loss: 1.6677\n",
      "Epochs: 2 batch_loss: 1.6577\n",
      "Epochs: 2 batch_loss: 1.7521\n",
      "Epochs: 2 batch_loss: 1.6554\n",
      "Epochs: 2 batch_loss: 1.9071\n",
      "Epochs: 2 batch_loss: 1.7908\n",
      "Epochs: 2 batch_loss: 1.7992\n",
      "Epochs: 2 batch_loss: 1.8476\n",
      "Epochs: 2 batch_loss: 1.6853\n",
      "Epochs: 2 batch_loss: 1.7114\n",
      "Epochs: 2 batch_loss: 1.6791\n",
      "Epochs: 2 batch_loss: 1.7365\n",
      "Epochs: 2 batch_loss: 1.6229\n",
      "Epochs: 2 batch_loss: 1.6243\n",
      "Epochs: 2 batch_loss: 1.7843\n",
      "Epochs: 2 batch_loss: 1.6786\n",
      "Epochs: 2 batch_loss: 1.5502\n",
      "Epochs: 2 batch_loss: 1.7245\n",
      "Epochs: 2 batch_loss: 1.6867\n",
      "Epochs: 2 batch_loss: 1.6105\n",
      "Epochs: 2 batch_loss: 1.7429\n",
      "Epochs: 2 batch_loss: 1.4562\n",
      "Epochs: 2 batch_loss: 1.6705\n",
      "Epochs: 2 batch_loss: 1.7306\n",
      "Epochs: 2 batch_loss: 1.7346\n",
      "Epochs: 2 batch_loss: 1.5479\n",
      "Epochs: 2 batch_loss: 1.6503\n",
      "Epochs: 2 batch_loss: 1.7491\n",
      "Epochs: 2/10 total_loss: 2.1373\n",
      "Epochs: 3 batch_loss: 1.5621\n",
      "Epochs: 3 batch_loss: 1.6232\n",
      "Epochs: 3 batch_loss: 1.5249\n",
      "Epochs: 3 batch_loss: 1.6318\n",
      "Epochs: 3 batch_loss: 1.5993\n",
      "Epochs: 3 batch_loss: 1.5823\n",
      "Epochs: 3 batch_loss: 1.4552\n",
      "Epochs: 3 batch_loss: 1.4902\n",
      "Epochs: 3 batch_loss: 1.4525\n",
      "Epochs: 3 batch_loss: 1.6073\n",
      "Epochs: 3 batch_loss: 1.5278\n",
      "Epochs: 3 batch_loss: 1.4812\n",
      "Epochs: 3 batch_loss: 1.5360\n",
      "Epochs: 3 batch_loss: 1.4849\n",
      "Epochs: 3 batch_loss: 1.4805\n",
      "Epochs: 3 batch_loss: 1.5496\n",
      "Epochs: 3 batch_loss: 1.5089\n",
      "Epochs: 3 batch_loss: 1.4950\n",
      "Epochs: 3 batch_loss: 1.4614\n",
      "Epochs: 3 batch_loss: 1.4011\n",
      "Epochs: 3 batch_loss: 1.6011\n",
      "Epochs: 3 batch_loss: 1.5478\n",
      "Epochs: 3 batch_loss: 1.3754\n",
      "Epochs: 3 batch_loss: 1.5931\n",
      "Epochs: 3 batch_loss: 1.5035\n",
      "Epochs: 3 batch_loss: 1.4039\n",
      "Epochs: 3 batch_loss: 1.3749\n",
      "Epochs: 3 batch_loss: 1.5856\n",
      "Epochs: 3 batch_loss: 1.3798\n",
      "Epochs: 3 batch_loss: 1.5797\n",
      "Epochs: 3 batch_loss: 1.5457\n",
      "Epochs: 3 batch_loss: 1.3740\n",
      "Epochs: 3 batch_loss: 1.3909\n",
      "Epochs: 3 batch_loss: 1.4658\n",
      "Epochs: 3 batch_loss: 1.4244\n",
      "Epochs: 3 batch_loss: 1.4305\n",
      "Epochs: 3 batch_loss: 1.4450\n",
      "Epochs: 3 batch_loss: 1.4402\n",
      "Epochs: 3 batch_loss: 1.4566\n",
      "Epochs: 3 batch_loss: 1.4830\n",
      "Epochs: 3 batch_loss: 1.4271\n",
      "Epochs: 3 batch_loss: 1.3459\n",
      "Epochs: 3 batch_loss: 1.5722\n",
      "Epochs: 3 batch_loss: 1.4225\n",
      "Epochs: 3 batch_loss: 1.2834\n",
      "Epochs: 3 batch_loss: 1.3728\n",
      "Epochs: 3 batch_loss: 1.4747\n",
      "Epochs: 3 batch_loss: 1.3712\n",
      "Epochs: 3 batch_loss: 1.3257\n",
      "Epochs: 3 batch_loss: 1.4861\n",
      "Epochs: 3 batch_loss: 1.3669\n",
      "Epochs: 3 batch_loss: 1.3470\n",
      "Epochs: 3 batch_loss: 1.3602\n",
      "Epochs: 3 batch_loss: 1.3400\n",
      "Epochs: 3 batch_loss: 1.2196\n",
      "Epochs: 3 batch_loss: 1.2456\n",
      "Epochs: 3 batch_loss: 1.3461\n",
      "Epochs: 3 batch_loss: 1.2470\n",
      "Epochs: 3 batch_loss: 1.3152\n",
      "Epochs: 3 batch_loss: 1.3477\n",
      "Epochs: 3 batch_loss: 1.4019\n",
      "Epochs: 3 batch_loss: 1.3017\n",
      "Epochs: 3 batch_loss: 1.3142\n",
      "Epochs: 3 batch_loss: 1.3661\n",
      "Epochs: 3 batch_loss: 1.2900\n",
      "Epochs: 3 batch_loss: 1.3225\n",
      "Epochs: 3 batch_loss: 1.2244\n",
      "Epochs: 3 batch_loss: 1.3618\n",
      "Epochs: 3 batch_loss: 1.2063\n",
      "Epochs: 3 batch_loss: 1.4228\n",
      "Epochs: 3 batch_loss: 1.3235\n",
      "Epochs: 3 batch_loss: 1.3879\n",
      "Epochs: 3 batch_loss: 1.5997\n",
      "Epochs: 3 batch_loss: 1.2746\n",
      "Epochs: 3 batch_loss: 1.2996\n",
      "Epochs: 3 batch_loss: 1.2520\n",
      "Epochs: 3 batch_loss: 1.2318\n",
      "Epochs: 3 batch_loss: 1.2919\n",
      "Epochs: 3 batch_loss: 1.2446\n",
      "Epochs: 3 batch_loss: 1.2399\n",
      "Epochs: 3 batch_loss: 1.3175\n",
      "Epochs: 3 batch_loss: 1.2539\n",
      "Epochs: 3 batch_loss: 1.2775\n",
      "Epochs: 3 batch_loss: 1.2519\n",
      "Epochs: 3 batch_loss: 1.2549\n",
      "Epochs: 3 batch_loss: 1.2678\n",
      "Epochs: 3 batch_loss: 1.3224\n",
      "Epochs: 3 batch_loss: 1.2104\n",
      "Epochs: 3 batch_loss: 1.2169\n",
      "Epochs: 3 batch_loss: 1.2703\n",
      "Epochs: 3 batch_loss: 1.1155\n",
      "Epochs: 3 batch_loss: 1.3201\n",
      "Epochs: 3 batch_loss: 1.2094\n",
      "Epochs: 3 batch_loss: 1.1701\n",
      "Epochs: 3 batch_loss: 1.0786\n",
      "Epochs: 3 batch_loss: 1.2386\n",
      "Epochs: 3 batch_loss: 1.2440\n",
      "Epochs: 3 batch_loss: 1.2424\n",
      "Epochs: 3 batch_loss: 1.1503\n",
      "Epochs: 3 batch_loss: 1.3214\n",
      "Epochs: 3 batch_loss: 1.1510\n",
      "Epochs: 3 batch_loss: 1.2058\n",
      "Epochs: 3 batch_loss: 1.1127\n",
      "Epochs: 3 batch_loss: 1.3365\n",
      "Epochs: 3 batch_loss: 1.1369\n",
      "Epochs: 3 batch_loss: 1.3191\n",
      "Epochs: 3 batch_loss: 1.2485\n",
      "Epochs: 3 batch_loss: 1.2134\n",
      "Epochs: 3 batch_loss: 1.1269\n",
      "Epochs: 3 batch_loss: 1.0974\n",
      "Epochs: 3 batch_loss: 1.3130\n",
      "Epochs: 3 batch_loss: 1.2376\n",
      "Epochs: 3 batch_loss: 1.1324\n",
      "Epochs: 3 batch_loss: 1.1329\n",
      "Epochs: 3 batch_loss: 1.2678\n",
      "Epochs: 3 batch_loss: 1.3007\n",
      "Epochs: 3 batch_loss: 1.2705\n",
      "Epochs: 3 batch_loss: 1.2099\n",
      "Epochs: 3 batch_loss: 1.1862\n",
      "Epochs: 3 batch_loss: 1.2622\n",
      "Epochs: 3 batch_loss: 1.2092\n",
      "Epochs: 3 batch_loss: 1.2598\n",
      "Epochs: 3 batch_loss: 1.1573\n",
      "Epochs: 3 batch_loss: 1.1086\n",
      "Epochs: 3 batch_loss: 1.1390\n",
      "Epochs: 3 batch_loss: 1.0937\n",
      "Epochs: 3 batch_loss: 1.1440\n",
      "Epochs: 3 batch_loss: 1.1848\n",
      "Epochs: 3 batch_loss: 1.1091\n",
      "Epochs: 3 batch_loss: 1.1548\n",
      "Epochs: 3 batch_loss: 1.1757\n",
      "Epochs: 3 batch_loss: 1.1830\n",
      "Epochs: 3 batch_loss: 1.0861\n",
      "Epochs: 3 batch_loss: 1.1866\n",
      "Epochs: 3 batch_loss: 1.0974\n",
      "Epochs: 3 batch_loss: 0.9765\n",
      "Epochs: 3 batch_loss: 1.3119\n",
      "Epochs: 3 batch_loss: 1.1084\n",
      "Epochs: 3 batch_loss: 1.1175\n",
      "Epochs: 3 batch_loss: 1.1211\n",
      "Epochs: 3 batch_loss: 1.0547\n",
      "Epochs: 3 batch_loss: 1.0816\n",
      "Epochs: 3 batch_loss: 1.0717\n",
      "Epochs: 3 batch_loss: 1.0617\n",
      "Epochs: 3 batch_loss: 1.1652\n",
      "Epochs: 3 batch_loss: 1.3447\n",
      "Epochs: 3 batch_loss: 1.1283\n",
      "Epochs: 3 batch_loss: 1.0789\n",
      "Epochs: 3 batch_loss: 1.2060\n",
      "Epochs: 3 batch_loss: 1.0981\n",
      "Epochs: 3 batch_loss: 0.9884\n",
      "Epochs: 3 batch_loss: 1.1111\n",
      "Epochs: 3 batch_loss: 1.1237\n",
      "Epochs: 3 batch_loss: 1.1213\n",
      "Epochs: 3 batch_loss: 1.0998\n",
      "Epochs: 3 batch_loss: 1.0814\n",
      "Epochs: 3 batch_loss: 1.1807\n",
      "Epochs: 3 batch_loss: 1.1054\n",
      "Epochs: 3 batch_loss: 1.0110\n",
      "Epochs: 3 batch_loss: 1.1110\n",
      "Epochs: 3 batch_loss: 1.3125\n",
      "Epochs: 3 batch_loss: 1.0624\n",
      "Epochs: 3 batch_loss: 1.1379\n",
      "Epochs: 3 batch_loss: 1.1842\n",
      "Epochs: 3 batch_loss: 1.1004\n",
      "Epochs: 3 batch_loss: 0.9967\n",
      "Epochs: 3 batch_loss: 1.0040\n",
      "Epochs: 3 batch_loss: 1.0826\n",
      "Epochs: 3 batch_loss: 1.1405\n",
      "Epochs: 3 batch_loss: 1.0317\n",
      "Epochs: 3 batch_loss: 0.9556\n",
      "Epochs: 3 batch_loss: 1.1005\n",
      "Epochs: 3 batch_loss: 0.9614\n",
      "Epochs: 3 batch_loss: 0.9847\n",
      "Epochs: 3 batch_loss: 1.0857\n",
      "Epochs: 3 batch_loss: 0.9844\n",
      "Epochs: 3 batch_loss: 0.9465\n",
      "Epochs: 3 batch_loss: 1.1552\n",
      "Epochs: 3 batch_loss: 0.9853\n",
      "Epochs: 3 batch_loss: 1.1103\n",
      "Epochs: 3 batch_loss: 1.0367\n",
      "Epochs: 3 batch_loss: 1.0018\n",
      "Epochs: 3 batch_loss: 1.0440\n",
      "Epochs: 3 batch_loss: 1.0102\n",
      "Epochs: 3 batch_loss: 1.0241\n",
      "Epochs: 3 batch_loss: 0.8700\n",
      "Epochs: 3 batch_loss: 0.9489\n",
      "Epochs: 3 batch_loss: 1.0967\n",
      "Epochs: 3 batch_loss: 0.9849\n",
      "Epochs: 3 batch_loss: 0.9845\n",
      "Epochs: 3 batch_loss: 0.9608\n",
      "Epochs: 3 batch_loss: 1.0421\n",
      "Epochs: 3 batch_loss: 0.9570\n",
      "Epochs: 3 batch_loss: 1.1189\n",
      "Epochs: 3 batch_loss: 1.1033\n",
      "Epochs: 3 batch_loss: 1.0523\n",
      "Epochs: 3 batch_loss: 1.0054\n",
      "Epochs: 3 batch_loss: 1.0460\n",
      "Epochs: 3 batch_loss: 0.9275\n",
      "Epochs: 3 batch_loss: 1.0498\n",
      "Epochs: 3 batch_loss: 1.0522\n",
      "Epochs: 3 batch_loss: 1.0659\n",
      "Epochs: 3 batch_loss: 1.0630\n",
      "Epochs: 3 batch_loss: 0.8792\n",
      "Epochs: 3 batch_loss: 0.9644\n",
      "Epochs: 3 batch_loss: 1.0474\n",
      "Epochs: 3 batch_loss: 1.0947\n",
      "Epochs: 4 batch_loss: 0.8993\n",
      "Epochs: 4 batch_loss: 0.9460\n",
      "Epochs: 4 batch_loss: 0.7543\n",
      "Epochs: 4 batch_loss: 0.8837\n",
      "Epochs: 4 batch_loss: 0.8513\n",
      "Epochs: 4 batch_loss: 0.9569\n",
      "Epochs: 4 batch_loss: 0.9208\n",
      "Epochs: 4 batch_loss: 0.9981\n",
      "Epochs: 4 batch_loss: 0.7572\n",
      "Epochs: 4 batch_loss: 0.8248\n",
      "Epochs: 4 batch_loss: 0.9250\n",
      "Epochs: 4 batch_loss: 0.8559\n",
      "Epochs: 4 batch_loss: 0.8201\n",
      "Epochs: 4 batch_loss: 0.9142\n",
      "Epochs: 4 batch_loss: 0.8877\n",
      "Epochs: 4 batch_loss: 0.9347\n",
      "Epochs: 4 batch_loss: 0.7750\n",
      "Epochs: 4 batch_loss: 0.7789\n",
      "Epochs: 4 batch_loss: 0.8574\n",
      "Epochs: 4 batch_loss: 0.8027\n",
      "Epochs: 4 batch_loss: 0.8173\n",
      "Epochs: 4 batch_loss: 0.8216\n",
      "Epochs: 4 batch_loss: 0.8157\n",
      "Epochs: 4 batch_loss: 0.8617\n",
      "Epochs: 4 batch_loss: 0.7797\n",
      "Epochs: 4 batch_loss: 0.9219\n",
      "Epochs: 4 batch_loss: 0.8486\n",
      "Epochs: 4 batch_loss: 0.8659\n",
      "Epochs: 4 batch_loss: 0.8518\n",
      "Epochs: 4 batch_loss: 0.8941\n",
      "Epochs: 4 batch_loss: 0.8268\n",
      "Epochs: 4 batch_loss: 0.8626\n",
      "Epochs: 4 batch_loss: 0.8224\n",
      "Epochs: 4 batch_loss: 0.7531\n",
      "Epochs: 4 batch_loss: 0.6782\n",
      "Epochs: 4 batch_loss: 0.7783\n",
      "Epochs: 4 batch_loss: 0.9120\n",
      "Epochs: 4 batch_loss: 0.8387\n",
      "Epochs: 4 batch_loss: 0.8274\n",
      "Epochs: 4 batch_loss: 0.7827\n",
      "Epochs: 4 batch_loss: 0.8151\n",
      "Epochs: 4 batch_loss: 0.8179\n",
      "Epochs: 4 batch_loss: 0.7925\n",
      "Epochs: 4 batch_loss: 0.8427\n",
      "Epochs: 4 batch_loss: 0.7874\n",
      "Epochs: 4 batch_loss: 0.8090\n",
      "Epochs: 4 batch_loss: 0.7998\n",
      "Epochs: 4 batch_loss: 0.8783\n",
      "Epochs: 4 batch_loss: 0.8506\n",
      "Epochs: 4 batch_loss: 0.8388\n",
      "Epochs: 4 batch_loss: 0.7686\n",
      "Epochs: 4 batch_loss: 0.7442\n",
      "Epochs: 4 batch_loss: 0.8421\n",
      "Epochs: 4 batch_loss: 0.8318\n",
      "Epochs: 4 batch_loss: 0.9302\n",
      "Epochs: 4 batch_loss: 0.8730\n",
      "Epochs: 4 batch_loss: 0.8893\n",
      "Epochs: 4 batch_loss: 0.8007\n",
      "Epochs: 4 batch_loss: 0.8151\n",
      "Epochs: 4 batch_loss: 0.8287\n",
      "Epochs: 4 batch_loss: 0.7582\n",
      "Epochs: 4 batch_loss: 0.8683\n",
      "Epochs: 4 batch_loss: 0.7893\n",
      "Epochs: 4 batch_loss: 0.7988\n",
      "Epochs: 4 batch_loss: 0.8619\n",
      "Epochs: 4 batch_loss: 0.8408\n",
      "Epochs: 4 batch_loss: 0.8114\n",
      "Epochs: 4 batch_loss: 0.8328\n",
      "Epochs: 4 batch_loss: 0.8890\n",
      "Epochs: 4 batch_loss: 0.8340\n",
      "Epochs: 4 batch_loss: 0.9098\n",
      "Epochs: 4 batch_loss: 0.8978\n",
      "Epochs: 4 batch_loss: 0.8000\n",
      "Epochs: 4 batch_loss: 0.8341\n",
      "Epochs: 4 batch_loss: 0.8287\n",
      "Epochs: 4 batch_loss: 0.9068\n",
      "Epochs: 4 batch_loss: 0.7823\n",
      "Epochs: 4 batch_loss: 0.8338\n",
      "Epochs: 4 batch_loss: 1.0459\n",
      "Epochs: 4 batch_loss: 0.8442\n",
      "Epochs: 4 batch_loss: 0.7641\n",
      "Epochs: 4 batch_loss: 0.7735\n",
      "Epochs: 4 batch_loss: 0.7137\n",
      "Epochs: 4 batch_loss: 0.7138\n",
      "Epochs: 4 batch_loss: 0.8253\n",
      "Epochs: 4 batch_loss: 0.7364\n",
      "Epochs: 4 batch_loss: 0.6927\n",
      "Epochs: 4 batch_loss: 0.7679\n",
      "Epochs: 4 batch_loss: 0.9712\n",
      "Epochs: 4 batch_loss: 0.8100\n",
      "Epochs: 4 batch_loss: 0.7692\n",
      "Epochs: 4 batch_loss: 0.6800\n",
      "Epochs: 4 batch_loss: 0.7339\n",
      "Epochs: 4 batch_loss: 0.7254\n",
      "Epochs: 4 batch_loss: 0.8142\n",
      "Epochs: 4 batch_loss: 0.7383\n",
      "Epochs: 4 batch_loss: 0.7784\n",
      "Epochs: 4 batch_loss: 0.8513\n",
      "Epochs: 4 batch_loss: 0.7457\n",
      "Epochs: 4 batch_loss: 0.6964\n",
      "Epochs: 4 batch_loss: 0.8731\n",
      "Epochs: 4 batch_loss: 0.8427\n",
      "Epochs: 4 batch_loss: 0.8066\n",
      "Epochs: 4 batch_loss: 0.8420\n",
      "Epochs: 4 batch_loss: 0.8387\n",
      "Epochs: 4 batch_loss: 0.8061\n",
      "Epochs: 4 batch_loss: 0.8036\n",
      "Epochs: 4 batch_loss: 0.6752\n",
      "Epochs: 4 batch_loss: 0.9499\n",
      "Epochs: 4 batch_loss: 0.7312\n",
      "Epochs: 4 batch_loss: 0.6685\n",
      "Epochs: 4 batch_loss: 0.8313\n",
      "Epochs: 4 batch_loss: 0.7447\n",
      "Epochs: 4 batch_loss: 0.8268\n",
      "Epochs: 4 batch_loss: 0.7006\n",
      "Epochs: 4 batch_loss: 0.7523\n",
      "Epochs: 4 batch_loss: 0.7769\n",
      "Epochs: 4 batch_loss: 0.7872\n",
      "Epochs: 4 batch_loss: 0.8229\n",
      "Epochs: 4 batch_loss: 0.7633\n",
      "Epochs: 4 batch_loss: 0.8545\n",
      "Epochs: 4 batch_loss: 0.7782\n",
      "Epochs: 4 batch_loss: 0.8424\n",
      "Epochs: 4 batch_loss: 0.7022\n",
      "Epochs: 4 batch_loss: 0.7781\n",
      "Epochs: 4 batch_loss: 0.7927\n",
      "Epochs: 4 batch_loss: 0.7538\n",
      "Epochs: 4 batch_loss: 0.7602\n",
      "Epochs: 4 batch_loss: 0.6981\n",
      "Epochs: 4 batch_loss: 0.8250\n",
      "Epochs: 4 batch_loss: 0.7744\n",
      "Epochs: 4 batch_loss: 0.8454\n",
      "Epochs: 4 batch_loss: 0.8594\n",
      "Epochs: 4 batch_loss: 0.7663\n",
      "Epochs: 4 batch_loss: 0.7695\n",
      "Epochs: 4 batch_loss: 0.7312\n",
      "Epochs: 4 batch_loss: 0.7285\n",
      "Epochs: 4 batch_loss: 0.7073\n",
      "Epochs: 4 batch_loss: 0.7394\n",
      "Epochs: 4 batch_loss: 0.7191\n",
      "Epochs: 4 batch_loss: 0.7300\n",
      "Epochs: 4 batch_loss: 0.7040\n",
      "Epochs: 4 batch_loss: 0.8282\n",
      "Epochs: 4 batch_loss: 0.7724\n",
      "Epochs: 4 batch_loss: 0.8280\n",
      "Epochs: 4 batch_loss: 0.8612\n",
      "Epochs: 4 batch_loss: 0.7620\n",
      "Epochs: 4 batch_loss: 0.7860\n",
      "Epochs: 4 batch_loss: 0.6963\n",
      "Epochs: 4 batch_loss: 0.8229\n",
      "Epochs: 4 batch_loss: 0.7474\n",
      "Epochs: 4 batch_loss: 0.7834\n",
      "Epochs: 4 batch_loss: 0.8309\n",
      "Epochs: 4 batch_loss: 0.7288\n",
      "Epochs: 4 batch_loss: 0.8263\n",
      "Epochs: 4 batch_loss: 0.7182\n",
      "Epochs: 4 batch_loss: 0.8143\n",
      "Epochs: 4 batch_loss: 0.8419\n",
      "Epochs: 4 batch_loss: 0.6876\n",
      "Epochs: 4 batch_loss: 0.8811\n",
      "Epochs: 4 batch_loss: 0.9074\n",
      "Epochs: 4 batch_loss: 0.7743\n",
      "Epochs: 4 batch_loss: 0.7128\n",
      "Epochs: 4 batch_loss: 0.7603\n",
      "Epochs: 4 batch_loss: 0.8159\n",
      "Epochs: 4 batch_loss: 0.7603\n",
      "Epochs: 4 batch_loss: 0.7753\n",
      "Epochs: 4 batch_loss: 0.7566\n",
      "Epochs: 4 batch_loss: 0.7825\n",
      "Epochs: 4 batch_loss: 0.7776\n",
      "Epochs: 4 batch_loss: 0.7862\n",
      "Epochs: 4 batch_loss: 0.8304\n",
      "Epochs: 4 batch_loss: 0.6406\n",
      "Epochs: 4 batch_loss: 0.6412\n",
      "Epochs: 4 batch_loss: 0.8411\n",
      "Epochs: 4 batch_loss: 0.7091\n",
      "Epochs: 4 batch_loss: 0.6972\n",
      "Epochs: 4 batch_loss: 0.6924\n",
      "Epochs: 4 batch_loss: 0.7493\n",
      "Epochs: 4 batch_loss: 0.6842\n",
      "Epochs: 4 batch_loss: 0.8269\n",
      "Epochs: 4 batch_loss: 0.7981\n",
      "Epochs: 4 batch_loss: 0.7200\n",
      "Epochs: 4 batch_loss: 0.7585\n",
      "Epochs: 4 batch_loss: 0.6568\n",
      "Epochs: 4 batch_loss: 0.7333\n",
      "Epochs: 4 batch_loss: 0.6161\n",
      "Epochs: 4 batch_loss: 0.6900\n",
      "Epochs: 4 batch_loss: 0.7549\n",
      "Epochs: 4 batch_loss: 0.8578\n",
      "Epochs: 4 batch_loss: 0.7703\n",
      "Epochs: 4 batch_loss: 0.6710\n",
      "Epochs: 4 batch_loss: 0.6883\n",
      "Epochs: 4 batch_loss: 0.7719\n",
      "Epochs: 4 batch_loss: 0.7963\n",
      "Epochs: 4 batch_loss: 0.8436\n",
      "Epochs: 4 batch_loss: 0.7472\n",
      "Epochs: 4 batch_loss: 0.6462\n",
      "Epochs: 4 batch_loss: 0.7787\n",
      "Epochs: 4 batch_loss: 0.7566\n",
      "Epochs: 4 batch_loss: 0.8297\n",
      "Epochs: 4 batch_loss: 0.7913\n",
      "Epochs: 4 batch_loss: 0.7832\n",
      "Epochs: 4 batch_loss: 0.6221\n",
      "Epochs: 4 batch_loss: 0.7273\n",
      "Epochs: 4 batch_loss: 0.5999\n",
      "Epochs: 4 batch_loss: 0.8026\n",
      "Epochs: 4/10 total_loss: 0.7957\n",
      "Epochs: 5 batch_loss: 0.7075\n",
      "Epochs: 5 batch_loss: 0.5880\n",
      "Epochs: 5 batch_loss: 0.4996\n",
      "Epochs: 5 batch_loss: 0.5607\n",
      "Epochs: 5 batch_loss: 0.5205\n",
      "Epochs: 5 batch_loss: 0.5738\n",
      "Epochs: 5 batch_loss: 0.5498\n",
      "Epochs: 5 batch_loss: 0.5063\n",
      "Epochs: 5 batch_loss: 0.5619\n",
      "Epochs: 5 batch_loss: 0.5992\n",
      "Epochs: 5 batch_loss: 0.6051\n",
      "Epochs: 5 batch_loss: 0.5678\n",
      "Epochs: 5 batch_loss: 0.6543\n",
      "Epochs: 5 batch_loss: 0.6641\n",
      "Epochs: 5 batch_loss: 0.5430\n",
      "Epochs: 5 batch_loss: 0.6174\n",
      "Epochs: 5 batch_loss: 0.5134\n",
      "Epochs: 5 batch_loss: 0.5691\n",
      "Epochs: 5 batch_loss: 0.5841\n",
      "Epochs: 5 batch_loss: 0.6441\n",
      "Epochs: 5 batch_loss: 0.5619\n",
      "Epochs: 5 batch_loss: 0.6170\n",
      "Epochs: 5 batch_loss: 0.5391\n",
      "Epochs: 5 batch_loss: 0.6003\n",
      "Epochs: 5 batch_loss: 0.5958\n",
      "Epochs: 5 batch_loss: 0.7510\n",
      "Epochs: 5 batch_loss: 0.5208\n",
      "Epochs: 5 batch_loss: 0.5095\n",
      "Epochs: 5 batch_loss: 0.5746\n",
      "Epochs: 5 batch_loss: 0.5422\n",
      "Epochs: 5 batch_loss: 0.5826\n",
      "Epochs: 5 batch_loss: 0.5553\n",
      "Epochs: 5 batch_loss: 0.4710\n",
      "Epochs: 5 batch_loss: 0.5513\n",
      "Epochs: 5 batch_loss: 0.6723\n",
      "Epochs: 5 batch_loss: 0.5507\n",
      "Epochs: 5 batch_loss: 0.6692\n",
      "Epochs: 5 batch_loss: 0.7071\n",
      "Epochs: 5 batch_loss: 0.5171\n",
      "Epochs: 5 batch_loss: 0.6099\n",
      "Epochs: 5 batch_loss: 0.6031\n",
      "Epochs: 5 batch_loss: 0.6058\n",
      "Epochs: 5 batch_loss: 0.6532\n",
      "Epochs: 5 batch_loss: 0.5768\n",
      "Epochs: 5 batch_loss: 0.6077\n",
      "Epochs: 5 batch_loss: 0.5940\n",
      "Epochs: 5 batch_loss: 0.5560\n",
      "Epochs: 5 batch_loss: 0.6508\n",
      "Epochs: 5 batch_loss: 0.6476\n",
      "Epochs: 5 batch_loss: 0.6653\n",
      "Epochs: 5 batch_loss: 0.5138\n",
      "Epochs: 5 batch_loss: 0.6583\n",
      "Epochs: 5 batch_loss: 0.5762\n",
      "Epochs: 5 batch_loss: 0.5716\n",
      "Epochs: 5 batch_loss: 0.6209\n",
      "Epochs: 5 batch_loss: 0.6008\n",
      "Epochs: 5 batch_loss: 0.5826\n",
      "Epochs: 5 batch_loss: 0.5552\n",
      "Epochs: 5 batch_loss: 0.6207\n",
      "Epochs: 5 batch_loss: 0.5312\n",
      "Epochs: 5 batch_loss: 0.5903\n",
      "Epochs: 5 batch_loss: 0.6731\n",
      "Epochs: 5 batch_loss: 0.7164\n",
      "Epochs: 5 batch_loss: 0.5244\n",
      "Epochs: 5 batch_loss: 0.5339\n",
      "Epochs: 5 batch_loss: 0.5881\n",
      "Epochs: 5 batch_loss: 0.6383\n",
      "Epochs: 5 batch_loss: 0.5545\n",
      "Epochs: 5 batch_loss: 0.5925\n",
      "Epochs: 5 batch_loss: 0.6122\n",
      "Epochs: 5 batch_loss: 0.5686\n",
      "Epochs: 5 batch_loss: 0.5367\n",
      "Epochs: 5 batch_loss: 0.6261\n",
      "Epochs: 5 batch_loss: 0.5514\n",
      "Epochs: 5 batch_loss: 0.5489\n",
      "Epochs: 5 batch_loss: 0.5818\n",
      "Epochs: 5 batch_loss: 0.6272\n",
      "Epochs: 5 batch_loss: 0.5412\n",
      "Epochs: 5 batch_loss: 0.6247\n",
      "Epochs: 5 batch_loss: 0.5551\n",
      "Epochs: 5 batch_loss: 0.6302\n",
      "Epochs: 5 batch_loss: 0.5968\n",
      "Epochs: 5 batch_loss: 0.5520\n",
      "Epochs: 5 batch_loss: 0.6260\n",
      "Epochs: 5 batch_loss: 0.6290\n",
      "Epochs: 5 batch_loss: 0.6013\n",
      "Epochs: 5 batch_loss: 0.6073\n",
      "Epochs: 5 batch_loss: 0.5533\n",
      "Epochs: 5 batch_loss: 0.7001\n",
      "Epochs: 5 batch_loss: 0.6290\n",
      "Epochs: 5 batch_loss: 0.5320\n",
      "Epochs: 5 batch_loss: 0.6061\n",
      "Epochs: 5 batch_loss: 0.5303\n",
      "Epochs: 5 batch_loss: 0.4341\n",
      "Epochs: 5 batch_loss: 0.6265\n",
      "Epochs: 5 batch_loss: 0.5725\n",
      "Epochs: 5 batch_loss: 0.5175\n",
      "Epochs: 5 batch_loss: 0.5111\n",
      "Epochs: 5 batch_loss: 0.5038\n",
      "Epochs: 5 batch_loss: 0.5720\n",
      "Epochs: 5 batch_loss: 0.6232\n",
      "Epochs: 5 batch_loss: 0.6143\n",
      "Epochs: 5 batch_loss: 0.6135\n",
      "Epochs: 5 batch_loss: 0.5735\n",
      "Epochs: 5 batch_loss: 0.6121\n",
      "Epochs: 5 batch_loss: 0.6722\n",
      "Epochs: 5 batch_loss: 0.6559\n",
      "Epochs: 5 batch_loss: 0.6718\n",
      "Epochs: 5 batch_loss: 0.5240\n",
      "Epochs: 5 batch_loss: 0.5153\n",
      "Epochs: 5 batch_loss: 0.6316\n",
      "Epochs: 5 batch_loss: 0.7294\n",
      "Epochs: 5 batch_loss: 0.5847\n",
      "Epochs: 5 batch_loss: 0.5510\n",
      "Epochs: 5 batch_loss: 0.6008\n",
      "Epochs: 5 batch_loss: 0.5773\n",
      "Epochs: 5 batch_loss: 0.6434\n",
      "Epochs: 5 batch_loss: 0.5408\n",
      "Epochs: 5 batch_loss: 0.5412\n",
      "Epochs: 5 batch_loss: 0.5115\n",
      "Epochs: 5 batch_loss: 0.4911\n",
      "Epochs: 5 batch_loss: 0.5327\n",
      "Epochs: 5 batch_loss: 0.6305\n",
      "Epochs: 5 batch_loss: 0.5592\n",
      "Epochs: 5 batch_loss: 0.7209\n",
      "Epochs: 5 batch_loss: 0.6208\n",
      "Epochs: 5 batch_loss: 0.4931\n",
      "Epochs: 5 batch_loss: 0.4600\n",
      "Epochs: 5 batch_loss: 0.5604\n",
      "Epochs: 5 batch_loss: 0.5278\n",
      "Epochs: 5 batch_loss: 0.6375\n",
      "Epochs: 5 batch_loss: 0.5966\n",
      "Epochs: 5 batch_loss: 0.5866\n",
      "Epochs: 5 batch_loss: 0.6056\n",
      "Epochs: 5 batch_loss: 0.6705\n",
      "Epochs: 5 batch_loss: 0.5271\n",
      "Epochs: 5 batch_loss: 0.5927\n",
      "Epochs: 5 batch_loss: 0.6030\n",
      "Epochs: 5 batch_loss: 0.5545\n",
      "Epochs: 5 batch_loss: 0.5902\n",
      "Epochs: 5 batch_loss: 0.6172\n",
      "Epochs: 5 batch_loss: 0.5674\n",
      "Epochs: 5 batch_loss: 0.6479\n",
      "Epochs: 5 batch_loss: 0.6005\n",
      "Epochs: 5 batch_loss: 0.5834\n",
      "Epochs: 5 batch_loss: 0.6777\n",
      "Epochs: 5 batch_loss: 0.5457\n",
      "Epochs: 5 batch_loss: 0.5794\n",
      "Epochs: 5 batch_loss: 0.6016\n",
      "Epochs: 5 batch_loss: 0.5757\n",
      "Epochs: 5 batch_loss: 0.5031\n",
      "Epochs: 5 batch_loss: 0.5706\n",
      "Epochs: 5 batch_loss: 0.4677\n",
      "Epochs: 5 batch_loss: 0.5524\n",
      "Epochs: 5 batch_loss: 0.5253\n",
      "Epochs: 5 batch_loss: 0.5485\n",
      "Epochs: 5 batch_loss: 0.4930\n",
      "Epochs: 5 batch_loss: 0.5137\n",
      "Epochs: 5 batch_loss: 0.5677\n",
      "Epochs: 5 batch_loss: 0.5853\n",
      "Epochs: 5 batch_loss: 0.5959\n",
      "Epochs: 5 batch_loss: 0.5308\n",
      "Epochs: 5 batch_loss: 0.5233\n",
      "Epochs: 5 batch_loss: 0.5598\n",
      "Epochs: 5 batch_loss: 0.5492\n",
      "Epochs: 5 batch_loss: 0.5381\n",
      "Epochs: 5 batch_loss: 0.6414\n",
      "Epochs: 5 batch_loss: 0.6464\n",
      "Epochs: 5 batch_loss: 0.6473\n",
      "Epochs: 5 batch_loss: 0.5291\n",
      "Epochs: 5 batch_loss: 0.5981\n",
      "Epochs: 5 batch_loss: 0.5672\n",
      "Epochs: 5 batch_loss: 0.5427\n",
      "Epochs: 5 batch_loss: 0.5358\n",
      "Epochs: 5 batch_loss: 0.5976\n",
      "Epochs: 5 batch_loss: 0.5547\n",
      "Epochs: 5 batch_loss: 0.5276\n",
      "Epochs: 5 batch_loss: 0.6061\n",
      "Epochs: 5 batch_loss: 0.5335\n",
      "Epochs: 5 batch_loss: 0.5900\n",
      "Epochs: 5 batch_loss: 0.5848\n",
      "Epochs: 5 batch_loss: 0.5875\n",
      "Epochs: 5 batch_loss: 0.5849\n",
      "Epochs: 5 batch_loss: 0.5548\n",
      "Epochs: 5 batch_loss: 0.4748\n",
      "Epochs: 5 batch_loss: 0.6209\n",
      "Epochs: 5 batch_loss: 0.6023\n",
      "Epochs: 5 batch_loss: 0.4631\n",
      "Epochs: 5 batch_loss: 0.6823\n",
      "Epochs: 5 batch_loss: 0.5872\n",
      "Epochs: 5 batch_loss: 0.5562\n",
      "Epochs: 5 batch_loss: 0.4574\n",
      "Epochs: 5 batch_loss: 0.5838\n",
      "Epochs: 5 batch_loss: 0.5226\n",
      "Epochs: 5 batch_loss: 0.5477\n",
      "Epochs: 5 batch_loss: 0.6369\n",
      "Epochs: 5 batch_loss: 0.5572\n",
      "Epochs: 5 batch_loss: 0.6178\n",
      "Epochs: 5 batch_loss: 0.6953\n",
      "Epochs: 5 batch_loss: 0.5638\n",
      "Epochs: 5 batch_loss: 0.5157\n",
      "Epochs: 5 batch_loss: 0.5969\n",
      "Epochs: 5 batch_loss: 0.5808\n",
      "Epochs: 5 batch_loss: 0.5662\n",
      "Epochs: 5 batch_loss: 0.5868\n",
      "Epochs: 5 batch_loss: 0.5748\n",
      "Epochs: 6 batch_loss: 0.4484\n",
      "Epochs: 6 batch_loss: 0.4191\n",
      "Epochs: 6 batch_loss: 0.3885\n",
      "Epochs: 6 batch_loss: 0.5085\n",
      "Epochs: 6 batch_loss: 0.3956\n",
      "Epochs: 6 batch_loss: 0.4527\n",
      "Epochs: 6 batch_loss: 0.3794\n",
      "Epochs: 6 batch_loss: 0.4401\n",
      "Epochs: 6 batch_loss: 0.4965\n",
      "Epochs: 6 batch_loss: 0.4408\n",
      "Epochs: 6 batch_loss: 0.3990\n",
      "Epochs: 6 batch_loss: 0.4271\n",
      "Epochs: 6 batch_loss: 0.4335\n",
      "Epochs: 6 batch_loss: 0.4092\n",
      "Epochs: 6 batch_loss: 0.3681\n",
      "Epochs: 6 batch_loss: 0.4822\n",
      "Epochs: 6 batch_loss: 0.4693\n",
      "Epochs: 6 batch_loss: 0.3838\n",
      "Epochs: 6 batch_loss: 0.3817\n",
      "Epochs: 6 batch_loss: 0.4912\n",
      "Epochs: 6 batch_loss: 0.5272\n",
      "Epochs: 6 batch_loss: 0.4955\n",
      "Epochs: 6 batch_loss: 0.4773\n",
      "Epochs: 6 batch_loss: 0.5547\n",
      "Epochs: 6 batch_loss: 0.4751\n",
      "Epochs: 6 batch_loss: 0.3825\n",
      "Epochs: 6 batch_loss: 0.3639\n",
      "Epochs: 6 batch_loss: 0.4235\n",
      "Epochs: 6 batch_loss: 0.4784\n",
      "Epochs: 6 batch_loss: 0.4686\n",
      "Epochs: 6 batch_loss: 0.4318\n",
      "Epochs: 6 batch_loss: 0.4835\n",
      "Epochs: 6 batch_loss: 0.4644\n",
      "Epochs: 6 batch_loss: 0.4567\n",
      "Epochs: 6 batch_loss: 0.3674\n",
      "Epochs: 6 batch_loss: 0.4539\n",
      "Epochs: 6 batch_loss: 0.4933\n",
      "Epochs: 6 batch_loss: 0.4434\n",
      "Epochs: 6 batch_loss: 0.4707\n",
      "Epochs: 6 batch_loss: 0.3789\n",
      "Epochs: 6 batch_loss: 0.4192\n",
      "Epochs: 6 batch_loss: 0.4073\n",
      "Epochs: 6 batch_loss: 0.4324\n",
      "Epochs: 6 batch_loss: 0.4040\n",
      "Epochs: 6 batch_loss: 0.4491\n",
      "Epochs: 6 batch_loss: 0.4828\n",
      "Epochs: 6 batch_loss: 0.4352\n",
      "Epochs: 6 batch_loss: 0.4783\n",
      "Epochs: 6 batch_loss: 0.4072\n",
      "Epochs: 6 batch_loss: 0.4388\n",
      "Epochs: 6 batch_loss: 0.4845\n",
      "Epochs: 6 batch_loss: 0.4979\n",
      "Epochs: 6 batch_loss: 0.4345\n",
      "Epochs: 6 batch_loss: 0.4459\n",
      "Epochs: 6 batch_loss: 0.4148\n",
      "Epochs: 6 batch_loss: 0.4828\n",
      "Epochs: 6 batch_loss: 0.4885\n",
      "Epochs: 6 batch_loss: 0.4792\n",
      "Epochs: 6 batch_loss: 0.4166\n",
      "Epochs: 6 batch_loss: 0.4334\n",
      "Epochs: 6 batch_loss: 0.4511\n",
      "Epochs: 6 batch_loss: 0.4819\n",
      "Epochs: 6 batch_loss: 0.3938\n",
      "Epochs: 6 batch_loss: 0.4232\n",
      "Epochs: 6 batch_loss: 0.4587\n",
      "Epochs: 6 batch_loss: 0.4318\n",
      "Epochs: 6 batch_loss: 0.5017\n",
      "Epochs: 6 batch_loss: 0.3842\n",
      "Epochs: 6 batch_loss: 0.4146\n",
      "Epochs: 6 batch_loss: 0.3966\n",
      "Epochs: 6 batch_loss: 0.4331\n",
      "Epochs: 6 batch_loss: 0.3957\n",
      "Epochs: 6 batch_loss: 0.3934\n",
      "Epochs: 6 batch_loss: 0.4645\n",
      "Epochs: 6 batch_loss: 0.4673\n",
      "Epochs: 6 batch_loss: 0.5184\n",
      "Epochs: 6 batch_loss: 0.3937\n",
      "Epochs: 6 batch_loss: 0.4158\n",
      "Epochs: 6 batch_loss: 0.4435\n",
      "Epochs: 6 batch_loss: 0.4079\n",
      "Epochs: 6 batch_loss: 0.4207\n",
      "Epochs: 6 batch_loss: 0.4740\n",
      "Epochs: 6 batch_loss: 0.4714\n",
      "Epochs: 6 batch_loss: 0.5098\n",
      "Epochs: 6 batch_loss: 0.3823\n",
      "Epochs: 6 batch_loss: 0.4967\n",
      "Epochs: 6 batch_loss: 0.4649\n",
      "Epochs: 6 batch_loss: 0.4827\n",
      "Epochs: 6 batch_loss: 0.4493\n",
      "Epochs: 6 batch_loss: 0.4484\n",
      "Epochs: 6 batch_loss: 0.4735\n",
      "Epochs: 6 batch_loss: 0.4471\n",
      "Epochs: 6 batch_loss: 0.4687\n",
      "Epochs: 6 batch_loss: 0.4430\n",
      "Epochs: 6 batch_loss: 0.5439\n",
      "Epochs: 6 batch_loss: 0.4731\n",
      "Epochs: 6 batch_loss: 0.4541\n",
      "Epochs: 6 batch_loss: 0.4161\n",
      "Epochs: 6 batch_loss: 0.4514\n",
      "Epochs: 6 batch_loss: 0.4795\n",
      "Epochs: 6 batch_loss: 0.4415\n",
      "Epochs: 6 batch_loss: 0.5017\n",
      "Epochs: 6 batch_loss: 0.4708\n",
      "Epochs: 6 batch_loss: 0.5474\n",
      "Epochs: 6 batch_loss: 0.4602\n",
      "Epochs: 6 batch_loss: 0.4923\n",
      "Epochs: 6 batch_loss: 0.5218\n",
      "Epochs: 6 batch_loss: 0.4939\n",
      "Epochs: 6 batch_loss: 0.4131\n",
      "Epochs: 6 batch_loss: 0.4582\n",
      "Epochs: 6 batch_loss: 0.4549\n",
      "Epochs: 6 batch_loss: 0.5048\n",
      "Epochs: 6 batch_loss: 0.4309\n",
      "Epochs: 6 batch_loss: 0.4804\n",
      "Epochs: 6 batch_loss: 0.4465\n",
      "Epochs: 6 batch_loss: 0.4770\n",
      "Epochs: 6 batch_loss: 0.4478\n",
      "Epochs: 6 batch_loss: 0.4404\n",
      "Epochs: 6 batch_loss: 0.4278\n",
      "Epochs: 6 batch_loss: 0.4574\n",
      "Epochs: 6 batch_loss: 0.5018\n",
      "Epochs: 6 batch_loss: 0.3799\n",
      "Epochs: 6 batch_loss: 0.4708\n",
      "Epochs: 6 batch_loss: 0.3948\n",
      "Epochs: 6 batch_loss: 0.4526\n",
      "Epochs: 6 batch_loss: 0.4554\n",
      "Epochs: 6 batch_loss: 0.4429\n",
      "Epochs: 6 batch_loss: 0.4342\n",
      "Epochs: 6 batch_loss: 0.4552\n",
      "Epochs: 6 batch_loss: 0.4843\n",
      "Epochs: 6 batch_loss: 0.4122\n",
      "Epochs: 6 batch_loss: 0.3657\n",
      "Epochs: 6 batch_loss: 0.4048\n",
      "Epochs: 6 batch_loss: 0.4317\n",
      "Epochs: 6 batch_loss: 0.4800\n",
      "Epochs: 6 batch_loss: 0.4682\n",
      "Epochs: 6 batch_loss: 0.4817\n",
      "Epochs: 6 batch_loss: 0.4242\n",
      "Epochs: 6 batch_loss: 0.4376\n",
      "Epochs: 6 batch_loss: 0.4614\n",
      "Epochs: 6 batch_loss: 0.4504\n",
      "Epochs: 6 batch_loss: 0.5214\n",
      "Epochs: 6 batch_loss: 0.4779\n",
      "Epochs: 6 batch_loss: 0.4104\n",
      "Epochs: 6 batch_loss: 0.4386\n",
      "Epochs: 6 batch_loss: 0.4233\n",
      "Epochs: 6 batch_loss: 0.4588\n",
      "Epochs: 6 batch_loss: 0.4809\n",
      "Epochs: 6 batch_loss: 0.4866\n",
      "Epochs: 6 batch_loss: 0.5195\n",
      "Epochs: 6 batch_loss: 0.4061\n",
      "Epochs: 6 batch_loss: 0.5156\n",
      "Epochs: 6 batch_loss: 0.4099\n",
      "Epochs: 6 batch_loss: 0.5395\n",
      "Epochs: 6 batch_loss: 0.4201\n",
      "Epochs: 6 batch_loss: 0.4358\n",
      "Epochs: 6 batch_loss: 0.4111\n",
      "Epochs: 6 batch_loss: 0.5124\n",
      "Epochs: 6 batch_loss: 0.4769\n",
      "Epochs: 6 batch_loss: 0.5805\n",
      "Epochs: 6 batch_loss: 0.4192\n",
      "Epochs: 6 batch_loss: 0.4046\n",
      "Epochs: 6 batch_loss: 0.3846\n",
      "Epochs: 6 batch_loss: 0.4725\n",
      "Epochs: 6 batch_loss: 0.4361\n",
      "Epochs: 6 batch_loss: 0.4954\n",
      "Epochs: 6 batch_loss: 0.4524\n",
      "Epochs: 6 batch_loss: 0.5000\n",
      "Epochs: 6 batch_loss: 0.3930\n",
      "Epochs: 6 batch_loss: 0.4614\n",
      "Epochs: 6 batch_loss: 0.4029\n",
      "Epochs: 6 batch_loss: 0.4675\n",
      "Epochs: 6 batch_loss: 0.4437\n",
      "Epochs: 6 batch_loss: 0.3782\n",
      "Epochs: 6 batch_loss: 0.4399\n",
      "Epochs: 6 batch_loss: 0.4200\n",
      "Epochs: 6 batch_loss: 0.4453\n",
      "Epochs: 6 batch_loss: 0.3913\n",
      "Epochs: 6 batch_loss: 0.5022\n",
      "Epochs: 6 batch_loss: 0.4063\n",
      "Epochs: 6 batch_loss: 0.4004\n",
      "Epochs: 6 batch_loss: 0.4762\n",
      "Epochs: 6 batch_loss: 0.5465\n",
      "Epochs: 6 batch_loss: 0.3289\n",
      "Epochs: 6 batch_loss: 0.4555\n",
      "Epochs: 6 batch_loss: 0.4042\n",
      "Epochs: 6 batch_loss: 0.5141\n",
      "Epochs: 6 batch_loss: 0.5028\n",
      "Epochs: 6 batch_loss: 0.4564\n",
      "Epochs: 6 batch_loss: 0.5706\n",
      "Epochs: 6 batch_loss: 0.4050\n",
      "Epochs: 6 batch_loss: 0.4089\n",
      "Epochs: 6 batch_loss: 0.4015\n",
      "Epochs: 6 batch_loss: 0.3911\n",
      "Epochs: 6 batch_loss: 0.4769\n",
      "Epochs: 6 batch_loss: 0.4849\n",
      "Epochs: 6 batch_loss: 0.4947\n",
      "Epochs: 6 batch_loss: 0.3749\n",
      "Epochs: 6 batch_loss: 0.4296\n",
      "Epochs: 6 batch_loss: 0.4706\n",
      "Epochs: 6 batch_loss: 0.4191\n",
      "Epochs: 6 batch_loss: 0.4138\n",
      "Epochs: 6 batch_loss: 0.4462\n",
      "Epochs: 6 batch_loss: 0.4278\n",
      "Epochs: 6 batch_loss: 0.4021\n",
      "Epochs: 6 batch_loss: 0.4358\n",
      "Epochs: 6 batch_loss: 0.3922\n",
      "Epochs: 6/10 total_loss: 0.4485\n",
      "Epochs: 7 batch_loss: 0.3814\n",
      "Epochs: 7 batch_loss: 0.2878\n",
      "Epochs: 7 batch_loss: 0.3185\n",
      "Epochs: 7 batch_loss: 0.3891\n",
      "Epochs: 7 batch_loss: 0.3356\n",
      "Epochs: 7 batch_loss: 0.2673\n",
      "Epochs: 7 batch_loss: 0.3661\n",
      "Epochs: 7 batch_loss: 0.3121\n",
      "Epochs: 7 batch_loss: 0.3753\n",
      "Epochs: 7 batch_loss: 0.3343\n",
      "Epochs: 7 batch_loss: 0.3374\n",
      "Epochs: 7 batch_loss: 0.3828\n",
      "Epochs: 7 batch_loss: 0.2948\n",
      "Epochs: 7 batch_loss: 0.3230\n",
      "Epochs: 7 batch_loss: 0.2758\n",
      "Epochs: 7 batch_loss: 0.2702\n",
      "Epochs: 7 batch_loss: 0.3443\n",
      "Epochs: 7 batch_loss: 0.3450\n",
      "Epochs: 7 batch_loss: 0.3328\n",
      "Epochs: 7 batch_loss: 0.3182\n",
      "Epochs: 7 batch_loss: 0.3925\n",
      "Epochs: 7 batch_loss: 0.3195\n",
      "Epochs: 7 batch_loss: 0.3104\n",
      "Epochs: 7 batch_loss: 0.3182\n",
      "Epochs: 7 batch_loss: 0.4129\n",
      "Epochs: 7 batch_loss: 0.4138\n",
      "Epochs: 7 batch_loss: 0.3901\n",
      "Epochs: 7 batch_loss: 0.3245\n",
      "Epochs: 7 batch_loss: 0.2950\n",
      "Epochs: 7 batch_loss: 0.2945\n",
      "Epochs: 7 batch_loss: 0.3028\n",
      "Epochs: 7 batch_loss: 0.3404\n",
      "Epochs: 7 batch_loss: 0.3569\n",
      "Epochs: 7 batch_loss: 0.3386\n",
      "Epochs: 7 batch_loss: 0.3223\n",
      "Epochs: 7 batch_loss: 0.3290\n",
      "Epochs: 7 batch_loss: 0.3221\n",
      "Epochs: 7 batch_loss: 0.3437\n",
      "Epochs: 7 batch_loss: 0.4188\n",
      "Epochs: 7 batch_loss: 0.3595\n",
      "Epochs: 7 batch_loss: 0.3809\n",
      "Epochs: 7 batch_loss: 0.2880\n",
      "Epochs: 7 batch_loss: 0.3411\n",
      "Epochs: 7 batch_loss: 0.4322\n",
      "Epochs: 7 batch_loss: 0.2998\n",
      "Epochs: 7 batch_loss: 0.3454\n",
      "Epochs: 7 batch_loss: 0.3795\n",
      "Epochs: 7 batch_loss: 0.3855\n",
      "Epochs: 7 batch_loss: 0.3514\n",
      "Epochs: 7 batch_loss: 0.4668\n",
      "Epochs: 7 batch_loss: 0.3413\n",
      "Epochs: 7 batch_loss: 0.3048\n",
      "Epochs: 7 batch_loss: 0.3534\n",
      "Epochs: 7 batch_loss: 0.3185\n",
      "Epochs: 7 batch_loss: 0.3663\n",
      "Epochs: 7 batch_loss: 0.3702\n",
      "Epochs: 7 batch_loss: 0.3320\n",
      "Epochs: 7 batch_loss: 0.3771\n",
      "Epochs: 7 batch_loss: 0.3338\n",
      "Epochs: 7 batch_loss: 0.3534\n",
      "Epochs: 7 batch_loss: 0.3234\n",
      "Epochs: 7 batch_loss: 0.4179\n",
      "Epochs: 7 batch_loss: 0.3928\n",
      "Epochs: 7 batch_loss: 0.3615\n",
      "Epochs: 7 batch_loss: 0.3759\n",
      "Epochs: 7 batch_loss: 0.3232\n",
      "Epochs: 7 batch_loss: 0.4302\n",
      "Epochs: 7 batch_loss: 0.4055\n",
      "Epochs: 7 batch_loss: 0.3507\n",
      "Epochs: 7 batch_loss: 0.4133\n",
      "Epochs: 7 batch_loss: 0.3830\n",
      "Epochs: 7 batch_loss: 0.4480\n",
      "Epochs: 7 batch_loss: 0.3839\n",
      "Epochs: 7 batch_loss: 0.3727\n",
      "Epochs: 7 batch_loss: 0.3731\n",
      "Epochs: 7 batch_loss: 0.3317\n",
      "Epochs: 7 batch_loss: 0.3899\n",
      "Epochs: 7 batch_loss: 0.4094\n",
      "Epochs: 7 batch_loss: 0.3570\n",
      "Epochs: 7 batch_loss: 0.3223\n",
      "Epochs: 7 batch_loss: 0.4112\n",
      "Epochs: 7 batch_loss: 0.3442\n",
      "Epochs: 7 batch_loss: 0.3753\n",
      "Epochs: 7 batch_loss: 0.3469\n",
      "Epochs: 7 batch_loss: 0.3991\n",
      "Epochs: 7 batch_loss: 0.4338\n",
      "Epochs: 7 batch_loss: 0.3046\n",
      "Epochs: 7 batch_loss: 0.3810\n",
      "Epochs: 7 batch_loss: 0.3388\n",
      "Epochs: 7 batch_loss: 0.3744\n",
      "Epochs: 7 batch_loss: 0.3702\n",
      "Epochs: 7 batch_loss: 0.3194\n",
      "Epochs: 7 batch_loss: 0.3968\n",
      "Epochs: 7 batch_loss: 0.4333\n",
      "Epochs: 7 batch_loss: 0.3787\n",
      "Epochs: 7 batch_loss: 0.3398\n",
      "Epochs: 7 batch_loss: 0.4463\n",
      "Epochs: 7 batch_loss: 0.4176\n",
      "Epochs: 7 batch_loss: 0.3845\n",
      "Epochs: 7 batch_loss: 0.3360\n",
      "Epochs: 7 batch_loss: 0.3763\n",
      "Epochs: 7 batch_loss: 0.3846\n",
      "Epochs: 7 batch_loss: 0.3081\n",
      "Epochs: 7 batch_loss: 0.2956\n",
      "Epochs: 7 batch_loss: 0.3558\n",
      "Epochs: 7 batch_loss: 0.3836\n",
      "Epochs: 7 batch_loss: 0.4130\n",
      "Epochs: 7 batch_loss: 0.4312\n",
      "Epochs: 7 batch_loss: 0.3013\n",
      "Epochs: 7 batch_loss: 0.3187\n",
      "Epochs: 7 batch_loss: 0.3596\n",
      "Epochs: 7 batch_loss: 0.3699\n",
      "Epochs: 7 batch_loss: 0.3494\n",
      "Epochs: 7 batch_loss: 0.3871\n",
      "Epochs: 7 batch_loss: 0.3178\n",
      "Epochs: 7 batch_loss: 0.3757\n",
      "Epochs: 7 batch_loss: 0.3308\n",
      "Epochs: 7 batch_loss: 0.3270\n",
      "Epochs: 7 batch_loss: 0.3381\n",
      "Epochs: 7 batch_loss: 0.3635\n",
      "Epochs: 7 batch_loss: 0.4205\n",
      "Epochs: 7 batch_loss: 0.3126\n",
      "Epochs: 7 batch_loss: 0.3674\n",
      "Epochs: 7 batch_loss: 0.3617\n",
      "Epochs: 7 batch_loss: 0.3494\n",
      "Epochs: 7 batch_loss: 0.2887\n",
      "Epochs: 7 batch_loss: 0.4102\n",
      "Epochs: 7 batch_loss: 0.3826\n",
      "Epochs: 7 batch_loss: 0.3760\n",
      "Epochs: 7 batch_loss: 0.3549\n",
      "Epochs: 7 batch_loss: 0.4040\n",
      "Epochs: 7 batch_loss: 0.3170\n",
      "Epochs: 7 batch_loss: 0.3579\n",
      "Epochs: 7 batch_loss: 0.3339\n",
      "Epochs: 7 batch_loss: 0.3673\n",
      "Epochs: 7 batch_loss: 0.3582\n",
      "Epochs: 7 batch_loss: 0.3086\n",
      "Epochs: 7 batch_loss: 0.4091\n",
      "Epochs: 7 batch_loss: 0.3717\n",
      "Epochs: 7 batch_loss: 0.3426\n",
      "Epochs: 7 batch_loss: 0.3927\n",
      "Epochs: 7 batch_loss: 0.4016\n",
      "Epochs: 7 batch_loss: 0.3870\n",
      "Epochs: 7 batch_loss: 0.3783\n",
      "Epochs: 7 batch_loss: 0.3378\n",
      "Epochs: 7 batch_loss: 0.3348\n",
      "Epochs: 7 batch_loss: 0.3585\n",
      "Epochs: 7 batch_loss: 0.3758\n",
      "Epochs: 7 batch_loss: 0.3637\n",
      "Epochs: 7 batch_loss: 0.3428\n",
      "Epochs: 7 batch_loss: 0.3859\n",
      "Epochs: 7 batch_loss: 0.4153\n",
      "Epochs: 7 batch_loss: 0.3200\n",
      "Epochs: 7 batch_loss: 0.3826\n",
      "Epochs: 7 batch_loss: 0.2964\n",
      "Epochs: 7 batch_loss: 0.3385\n",
      "Epochs: 7 batch_loss: 0.3498\n",
      "Epochs: 7 batch_loss: 0.3350\n",
      "Epochs: 7 batch_loss: 0.3233\n",
      "Epochs: 7 batch_loss: 0.3568\n",
      "Epochs: 7 batch_loss: 0.3409\n",
      "Epochs: 7 batch_loss: 0.3836\n",
      "Epochs: 7 batch_loss: 0.3249\n",
      "Epochs: 7 batch_loss: 0.4245\n",
      "Epochs: 7 batch_loss: 0.3476\n",
      "Epochs: 7 batch_loss: 0.3420\n",
      "Epochs: 7 batch_loss: 0.3541\n",
      "Epochs: 7 batch_loss: 0.3469\n",
      "Epochs: 7 batch_loss: 0.3224\n",
      "Epochs: 7 batch_loss: 0.3361\n",
      "Epochs: 7 batch_loss: 0.2668\n",
      "Epochs: 7 batch_loss: 0.4076\n",
      "Epochs: 7 batch_loss: 0.3619\n",
      "Epochs: 7 batch_loss: 0.4316\n",
      "Epochs: 7 batch_loss: 0.3985\n",
      "Epochs: 7 batch_loss: 0.3405\n",
      "Epochs: 7 batch_loss: 0.3930\n",
      "Epochs: 7 batch_loss: 0.4432\n",
      "Epochs: 7 batch_loss: 0.4904\n",
      "Epochs: 7 batch_loss: 0.3440\n",
      "Epochs: 7 batch_loss: 0.4341\n",
      "Epochs: 7 batch_loss: 0.3578\n",
      "Epochs: 7 batch_loss: 0.3706\n",
      "Epochs: 7 batch_loss: 0.3475\n",
      "Epochs: 7 batch_loss: 0.3675\n",
      "Epochs: 7 batch_loss: 0.4031\n",
      "Epochs: 7 batch_loss: 0.3927\n",
      "Epochs: 7 batch_loss: 0.3950\n",
      "Epochs: 7 batch_loss: 0.3921\n",
      "Epochs: 7 batch_loss: 0.3106\n",
      "Epochs: 7 batch_loss: 0.4061\n",
      "Epochs: 7 batch_loss: 0.3124\n",
      "Epochs: 7 batch_loss: 0.3645\n",
      "Epochs: 7 batch_loss: 0.4388\n",
      "Epochs: 7 batch_loss: 0.3751\n",
      "Epochs: 7 batch_loss: 0.3419\n",
      "Epochs: 7 batch_loss: 0.3320\n",
      "Epochs: 7 batch_loss: 0.3440\n",
      "Epochs: 7 batch_loss: 0.4056\n",
      "Epochs: 7 batch_loss: 0.3480\n",
      "Epochs: 7 batch_loss: 0.3613\n",
      "Epochs: 7 batch_loss: 0.3947\n",
      "Epochs: 7 batch_loss: 0.3943\n",
      "Epochs: 7 batch_loss: 0.3235\n",
      "Epochs: 7 batch_loss: 0.3549\n",
      "Epochs: 7 batch_loss: 0.4248\n",
      "Epochs: 7 batch_loss: 0.3792\n",
      "Epochs: 8 batch_loss: 0.3074\n",
      "Epochs: 8 batch_loss: 0.3282\n",
      "Epochs: 8 batch_loss: 0.3438\n",
      "Epochs: 8 batch_loss: 0.3058\n",
      "Epochs: 8 batch_loss: 0.3171\n",
      "Epochs: 8 batch_loss: 0.2811\n",
      "Epochs: 8 batch_loss: 0.3305\n",
      "Epochs: 8 batch_loss: 0.2670\n",
      "Epochs: 8 batch_loss: 0.3004\n",
      "Epochs: 8 batch_loss: 0.3024\n",
      "Epochs: 8 batch_loss: 0.3432\n",
      "Epochs: 8 batch_loss: 0.2704\n",
      "Epochs: 8 batch_loss: 0.2193\n",
      "Epochs: 8 batch_loss: 0.2658\n",
      "Epochs: 8 batch_loss: 0.2749\n",
      "Epochs: 8 batch_loss: 0.2474\n",
      "Epochs: 8 batch_loss: 0.3136\n",
      "Epochs: 8 batch_loss: 0.3115\n",
      "Epochs: 8 batch_loss: 0.2740\n",
      "Epochs: 8 batch_loss: 0.2605\n",
      "Epochs: 8 batch_loss: 0.2397\n",
      "Epochs: 8 batch_loss: 0.3428\n",
      "Epochs: 8 batch_loss: 0.2719\n",
      "Epochs: 8 batch_loss: 0.2982\n",
      "Epochs: 8 batch_loss: 0.2993\n",
      "Epochs: 8 batch_loss: 0.2632\n",
      "Epochs: 8 batch_loss: 0.2669\n",
      "Epochs: 8 batch_loss: 0.2998\n",
      "Epochs: 8 batch_loss: 0.2906\n",
      "Epochs: 8 batch_loss: 0.2887\n",
      "Epochs: 8 batch_loss: 0.3015\n",
      "Epochs: 8 batch_loss: 0.2745\n",
      "Epochs: 8 batch_loss: 0.2734\n",
      "Epochs: 8 batch_loss: 0.3302\n",
      "Epochs: 8 batch_loss: 0.2893\n",
      "Epochs: 8 batch_loss: 0.3036\n",
      "Epochs: 8 batch_loss: 0.2480\n",
      "Epochs: 8 batch_loss: 0.2467\n",
      "Epochs: 8 batch_loss: 0.2433\n",
      "Epochs: 8 batch_loss: 0.2765\n",
      "Epochs: 8 batch_loss: 0.3072\n",
      "Epochs: 8 batch_loss: 0.3054\n",
      "Epochs: 8 batch_loss: 0.2117\n",
      "Epochs: 8 batch_loss: 0.2823\n",
      "Epochs: 8 batch_loss: 0.2686\n",
      "Epochs: 8 batch_loss: 0.3082\n",
      "Epochs: 8 batch_loss: 0.3037\n",
      "Epochs: 8 batch_loss: 0.2946\n",
      "Epochs: 8 batch_loss: 0.3038\n",
      "Epochs: 8 batch_loss: 0.3676\n",
      "Epochs: 8 batch_loss: 0.2682\n",
      "Epochs: 8 batch_loss: 0.2743\n",
      "Epochs: 8 batch_loss: 0.2968\n",
      "Epochs: 8 batch_loss: 0.3887\n",
      "Epochs: 8 batch_loss: 0.2493\n",
      "Epochs: 8 batch_loss: 0.2747\n",
      "Epochs: 8 batch_loss: 0.2408\n",
      "Epochs: 8 batch_loss: 0.2986\n",
      "Epochs: 8 batch_loss: 0.2803\n",
      "Epochs: 8 batch_loss: 0.2684\n",
      "Epochs: 8 batch_loss: 0.3836\n",
      "Epochs: 8 batch_loss: 0.2315\n",
      "Epochs: 8 batch_loss: 0.2615\n",
      "Epochs: 8 batch_loss: 0.2875\n",
      "Epochs: 8 batch_loss: 0.2796\n",
      "Epochs: 8 batch_loss: 0.3391\n",
      "Epochs: 8 batch_loss: 0.2806\n",
      "Epochs: 8 batch_loss: 0.2910\n",
      "Epochs: 8 batch_loss: 0.3478\n",
      "Epochs: 8 batch_loss: 0.2549\n",
      "Epochs: 8 batch_loss: 0.3320\n",
      "Epochs: 8 batch_loss: 0.2661\n",
      "Epochs: 8 batch_loss: 0.3169\n",
      "Epochs: 8 batch_loss: 0.2861\n",
      "Epochs: 8 batch_loss: 0.2432\n",
      "Epochs: 8 batch_loss: 0.3209\n",
      "Epochs: 8 batch_loss: 0.2859\n",
      "Epochs: 8 batch_loss: 0.3214\n",
      "Epochs: 8 batch_loss: 0.2815\n",
      "Epochs: 8 batch_loss: 0.2541\n",
      "Epochs: 8 batch_loss: 0.2956\n",
      "Epochs: 8 batch_loss: 0.3053\n",
      "Epochs: 8 batch_loss: 0.2735\n",
      "Epochs: 8 batch_loss: 0.3061\n",
      "Epochs: 8 batch_loss: 0.3229\n",
      "Epochs: 8 batch_loss: 0.2980\n",
      "Epochs: 8 batch_loss: 0.3215\n",
      "Epochs: 8 batch_loss: 0.2843\n",
      "Epochs: 8 batch_loss: 0.3186\n",
      "Epochs: 8 batch_loss: 0.3089\n",
      "Epochs: 8 batch_loss: 0.2690\n",
      "Epochs: 8 batch_loss: 0.3240\n",
      "Epochs: 8 batch_loss: 0.2867\n",
      "Epochs: 8 batch_loss: 0.3027\n",
      "Epochs: 8 batch_loss: 0.2994\n",
      "Epochs: 8 batch_loss: 0.3075\n",
      "Epochs: 8 batch_loss: 0.2662\n",
      "Epochs: 8 batch_loss: 0.3076\n",
      "Epochs: 8 batch_loss: 0.3073\n",
      "Epochs: 8 batch_loss: 0.2742\n",
      "Epochs: 8 batch_loss: 0.3485\n",
      "Epochs: 8 batch_loss: 0.3347\n",
      "Epochs: 8 batch_loss: 0.2905\n",
      "Epochs: 8 batch_loss: 0.3173\n",
      "Epochs: 8 batch_loss: 0.2941\n",
      "Epochs: 8 batch_loss: 0.2645\n",
      "Epochs: 8 batch_loss: 0.3183\n",
      "Epochs: 8 batch_loss: 0.2891\n",
      "Epochs: 8 batch_loss: 0.2936\n",
      "Epochs: 8 batch_loss: 0.2521\n",
      "Epochs: 8 batch_loss: 0.2872\n",
      "Epochs: 8 batch_loss: 0.3392\n",
      "Epochs: 8 batch_loss: 0.3134\n",
      "Epochs: 8 batch_loss: 0.2389\n",
      "Epochs: 8 batch_loss: 0.3319\n",
      "Epochs: 8 batch_loss: 0.3216\n",
      "Epochs: 8 batch_loss: 0.3091\n",
      "Epochs: 8 batch_loss: 0.2775\n",
      "Epochs: 8 batch_loss: 0.2661\n",
      "Epochs: 8 batch_loss: 0.3193\n",
      "Epochs: 8 batch_loss: 0.3040\n",
      "Epochs: 8 batch_loss: 0.3980\n",
      "Epochs: 8 batch_loss: 0.3405\n",
      "Epochs: 8 batch_loss: 0.3083\n",
      "Epochs: 8 batch_loss: 0.3266\n",
      "Epochs: 8 batch_loss: 0.3330\n",
      "Epochs: 8 batch_loss: 0.3283\n",
      "Epochs: 8 batch_loss: 0.3550\n",
      "Epochs: 8 batch_loss: 0.2260\n",
      "Epochs: 8 batch_loss: 0.2967\n",
      "Epochs: 8 batch_loss: 0.3201\n",
      "Epochs: 8 batch_loss: 0.3519\n",
      "Epochs: 8 batch_loss: 0.3125\n",
      "Epochs: 8 batch_loss: 0.3241\n",
      "Epochs: 8 batch_loss: 0.2674\n",
      "Epochs: 8 batch_loss: 0.2908\n",
      "Epochs: 8 batch_loss: 0.3252\n",
      "Epochs: 8 batch_loss: 0.3425\n",
      "Epochs: 8 batch_loss: 0.3052\n",
      "Epochs: 8 batch_loss: 0.2693\n",
      "Epochs: 8 batch_loss: 0.2724\n",
      "Epochs: 8 batch_loss: 0.2823\n",
      "Epochs: 8 batch_loss: 0.2764\n",
      "Epochs: 8 batch_loss: 0.3265\n",
      "Epochs: 8 batch_loss: 0.2777\n",
      "Epochs: 8 batch_loss: 0.3560\n",
      "Epochs: 8 batch_loss: 0.3039\n",
      "Epochs: 8 batch_loss: 0.3190\n",
      "Epochs: 8 batch_loss: 0.2903\n",
      "Epochs: 8 batch_loss: 0.3191\n",
      "Epochs: 8 batch_loss: 0.3140\n",
      "Epochs: 8 batch_loss: 0.3236\n",
      "Epochs: 8 batch_loss: 0.3342\n",
      "Epochs: 8 batch_loss: 0.4168\n",
      "Epochs: 8 batch_loss: 0.3120\n",
      "Epochs: 8 batch_loss: 0.3196\n",
      "Epochs: 8 batch_loss: 0.2880\n",
      "Epochs: 8 batch_loss: 0.2855\n",
      "Epochs: 8 batch_loss: 0.2866\n",
      "Epochs: 8 batch_loss: 0.3797\n",
      "Epochs: 8 batch_loss: 0.2997\n",
      "Epochs: 8 batch_loss: 0.3443\n",
      "Epochs: 8 batch_loss: 0.3041\n",
      "Epochs: 8 batch_loss: 0.3185\n",
      "Epochs: 8 batch_loss: 0.3335\n",
      "Epochs: 8 batch_loss: 0.2846\n",
      "Epochs: 8 batch_loss: 0.3120\n",
      "Epochs: 8 batch_loss: 0.2825\n",
      "Epochs: 8 batch_loss: 0.2999\n",
      "Epochs: 8 batch_loss: 0.3436\n",
      "Epochs: 8 batch_loss: 0.3169\n",
      "Epochs: 8 batch_loss: 0.2921\n",
      "Epochs: 8 batch_loss: 0.3771\n",
      "Epochs: 8 batch_loss: 0.3074\n",
      "Epochs: 8 batch_loss: 0.2529\n",
      "Epochs: 8 batch_loss: 0.3087\n",
      "Epochs: 8 batch_loss: 0.3072\n",
      "Epochs: 8 batch_loss: 0.2718\n",
      "Epochs: 8 batch_loss: 0.2737\n",
      "Epochs: 8 batch_loss: 0.3230\n",
      "Epochs: 8 batch_loss: 0.3291\n",
      "Epochs: 8 batch_loss: 0.3085\n",
      "Epochs: 8 batch_loss: 0.2786\n",
      "Epochs: 8 batch_loss: 0.3627\n",
      "Epochs: 8 batch_loss: 0.2931\n",
      "Epochs: 8 batch_loss: 0.3294\n",
      "Epochs: 8 batch_loss: 0.2826\n",
      "Epochs: 8 batch_loss: 0.3043\n",
      "Epochs: 8 batch_loss: 0.2739\n",
      "Epochs: 8 batch_loss: 0.3178\n",
      "Epochs: 8 batch_loss: 0.3142\n",
      "Epochs: 8 batch_loss: 0.2441\n",
      "Epochs: 8 batch_loss: 0.2868\n",
      "Epochs: 8 batch_loss: 0.2717\n",
      "Epochs: 8 batch_loss: 0.3407\n",
      "Epochs: 8 batch_loss: 0.3538\n",
      "Epochs: 8 batch_loss: 0.3281\n",
      "Epochs: 8 batch_loss: 0.3496\n",
      "Epochs: 8 batch_loss: 0.2821\n",
      "Epochs: 8 batch_loss: 0.2941\n",
      "Epochs: 8 batch_loss: 0.3355\n",
      "Epochs: 8 batch_loss: 0.2693\n",
      "Epochs: 8 batch_loss: 0.3326\n",
      "Epochs: 8 batch_loss: 0.3665\n",
      "Epochs: 8 batch_loss: 0.3026\n",
      "Epochs: 8 batch_loss: 0.2861\n",
      "Epochs: 8 batch_loss: 0.3270\n",
      "Epochs: 8/10 total_loss: 0.2993\n",
      "Epochs: 9 batch_loss: 0.2163\n",
      "Epochs: 9 batch_loss: 0.2025\n",
      "Epochs: 9 batch_loss: 0.2384\n",
      "Epochs: 9 batch_loss: 0.2070\n",
      "Epochs: 9 batch_loss: 0.2353\n",
      "Epochs: 9 batch_loss: 0.2332\n",
      "Epochs: 9 batch_loss: 0.2344\n",
      "Epochs: 9 batch_loss: 0.2169\n",
      "Epochs: 9 batch_loss: 0.2136\n",
      "Epochs: 9 batch_loss: 0.2229\n",
      "Epochs: 9 batch_loss: 0.2582\n",
      "Epochs: 9 batch_loss: 0.2181\n",
      "Epochs: 9 batch_loss: 0.2423\n",
      "Epochs: 9 batch_loss: 0.1958\n",
      "Epochs: 9 batch_loss: 0.2072\n",
      "Epochs: 9 batch_loss: 0.2339\n",
      "Epochs: 9 batch_loss: 0.2697\n",
      "Epochs: 9 batch_loss: 0.2337\n",
      "Epochs: 9 batch_loss: 0.2107\n",
      "Epochs: 9 batch_loss: 0.2647\n",
      "Epochs: 9 batch_loss: 0.2708\n",
      "Epochs: 9 batch_loss: 0.2198\n",
      "Epochs: 9 batch_loss: 0.2234\n",
      "Epochs: 9 batch_loss: 0.2069\n",
      "Epochs: 9 batch_loss: 0.2075\n",
      "Epochs: 9 batch_loss: 0.2196\n",
      "Epochs: 9 batch_loss: 0.2657\n",
      "Epochs: 9 batch_loss: 0.2759\n",
      "Epochs: 9 batch_loss: 0.2419\n",
      "Epochs: 9 batch_loss: 0.2452\n",
      "Epochs: 9 batch_loss: 0.2311\n",
      "Epochs: 9 batch_loss: 0.2873\n",
      "Epochs: 9 batch_loss: 0.2554\n",
      "Epochs: 9 batch_loss: 0.2251\n",
      "Epochs: 9 batch_loss: 0.2328\n",
      "Epochs: 9 batch_loss: 0.2743\n",
      "Epochs: 9 batch_loss: 0.2278\n",
      "Epochs: 9 batch_loss: 0.2605\n",
      "Epochs: 9 batch_loss: 0.2079\n",
      "Epochs: 9 batch_loss: 0.2570\n",
      "Epochs: 9 batch_loss: 0.2006\n",
      "Epochs: 9 batch_loss: 0.2573\n",
      "Epochs: 9 batch_loss: 0.2757\n",
      "Epochs: 9 batch_loss: 0.2674\n",
      "Epochs: 9 batch_loss: 0.2132\n",
      "Epochs: 9 batch_loss: 0.2044\n",
      "Epochs: 9 batch_loss: 0.2328\n",
      "Epochs: 9 batch_loss: 0.2197\n",
      "Epochs: 9 batch_loss: 0.2282\n",
      "Epochs: 9 batch_loss: 0.3143\n",
      "Epochs: 9 batch_loss: 0.2645\n",
      "Epochs: 9 batch_loss: 0.2324\n",
      "Epochs: 9 batch_loss: 0.2429\n",
      "Epochs: 9 batch_loss: 0.2165\n",
      "Epochs: 9 batch_loss: 0.3250\n",
      "Epochs: 9 batch_loss: 0.2351\n",
      "Epochs: 9 batch_loss: 0.2503\n",
      "Epochs: 9 batch_loss: 0.2043\n",
      "Epochs: 9 batch_loss: 0.2710\n",
      "Epochs: 9 batch_loss: 0.2175\n",
      "Epochs: 9 batch_loss: 0.2659\n",
      "Epochs: 9 batch_loss: 0.2280\n",
      "Epochs: 9 batch_loss: 0.2747\n",
      "Epochs: 9 batch_loss: 0.2590\n",
      "Epochs: 9 batch_loss: 0.2584\n",
      "Epochs: 9 batch_loss: 0.2078\n",
      "Epochs: 9 batch_loss: 0.2544\n",
      "Epochs: 9 batch_loss: 0.2480\n",
      "Epochs: 9 batch_loss: 0.2209\n",
      "Epochs: 9 batch_loss: 0.3051\n",
      "Epochs: 9 batch_loss: 0.3042\n",
      "Epochs: 9 batch_loss: 0.2746\n",
      "Epochs: 9 batch_loss: 0.2066\n",
      "Epochs: 9 batch_loss: 0.2367\n",
      "Epochs: 9 batch_loss: 0.2288\n",
      "Epochs: 9 batch_loss: 0.3008\n",
      "Epochs: 9 batch_loss: 0.2999\n",
      "Epochs: 9 batch_loss: 0.2601\n",
      "Epochs: 9 batch_loss: 0.3046\n",
      "Epochs: 9 batch_loss: 0.2352\n",
      "Epochs: 9 batch_loss: 0.2366\n",
      "Epochs: 9 batch_loss: 0.2124\n",
      "Epochs: 9 batch_loss: 0.2555\n",
      "Epochs: 9 batch_loss: 0.2681\n",
      "Epochs: 9 batch_loss: 0.2279\n",
      "Epochs: 9 batch_loss: 0.2364\n",
      "Epochs: 9 batch_loss: 0.2150\n",
      "Epochs: 9 batch_loss: 0.2119\n",
      "Epochs: 9 batch_loss: 0.2038\n",
      "Epochs: 9 batch_loss: 0.2108\n",
      "Epochs: 9 batch_loss: 0.2128\n",
      "Epochs: 9 batch_loss: 0.2717\n",
      "Epochs: 9 batch_loss: 0.2063\n",
      "Epochs: 9 batch_loss: 0.2958\n",
      "Epochs: 9 batch_loss: 0.3172\n",
      "Epochs: 9 batch_loss: 0.2422\n",
      "Epochs: 9 batch_loss: 0.2826\n",
      "Epochs: 9 batch_loss: 0.2133\n",
      "Epochs: 9 batch_loss: 0.2743\n",
      "Epochs: 9 batch_loss: 0.2804\n",
      "Epochs: 9 batch_loss: 0.2439\n",
      "Epochs: 9 batch_loss: 0.2274\n",
      "Epochs: 9 batch_loss: 0.2952\n",
      "Epochs: 9 batch_loss: 0.2372\n",
      "Epochs: 9 batch_loss: 0.2470\n",
      "Epochs: 9 batch_loss: 0.2041\n",
      "Epochs: 9 batch_loss: 0.2916\n",
      "Epochs: 9 batch_loss: 0.2733\n",
      "Epochs: 9 batch_loss: 0.1769\n",
      "Epochs: 9 batch_loss: 0.2680\n",
      "Epochs: 9 batch_loss: 0.2089\n",
      "Epochs: 9 batch_loss: 0.2096\n",
      "Epochs: 9 batch_loss: 0.2871\n",
      "Epochs: 9 batch_loss: 0.3033\n",
      "Epochs: 9 batch_loss: 0.2363\n",
      "Epochs: 9 batch_loss: 0.2965\n",
      "Epochs: 9 batch_loss: 0.2369\n",
      "Epochs: 9 batch_loss: 0.2661\n",
      "Epochs: 9 batch_loss: 0.2706\n",
      "Epochs: 9 batch_loss: 0.2279\n",
      "Epochs: 9 batch_loss: 0.2617\n",
      "Epochs: 9 batch_loss: 0.3107\n",
      "Epochs: 9 batch_loss: 0.2417\n",
      "Epochs: 9 batch_loss: 0.1963\n",
      "Epochs: 9 batch_loss: 0.2644\n",
      "Epochs: 9 batch_loss: 0.3170\n",
      "Epochs: 9 batch_loss: 0.2408\n",
      "Epochs: 9 batch_loss: 0.2792\n",
      "Epochs: 9 batch_loss: 0.2120\n",
      "Epochs: 9 batch_loss: 0.2357\n",
      "Epochs: 9 batch_loss: 0.2506\n",
      "Epochs: 9 batch_loss: 0.2385\n",
      "Epochs: 9 batch_loss: 0.2610\n",
      "Epochs: 9 batch_loss: 0.2255\n",
      "Epochs: 9 batch_loss: 0.3162\n",
      "Epochs: 9 batch_loss: 0.2567\n",
      "Epochs: 9 batch_loss: 0.3265\n",
      "Epochs: 9 batch_loss: 0.3214\n",
      "Epochs: 9 batch_loss: 0.2452\n",
      "Epochs: 9 batch_loss: 0.2257\n",
      "Epochs: 9 batch_loss: 0.2474\n",
      "Epochs: 9 batch_loss: 0.2418\n",
      "Epochs: 9 batch_loss: 0.2165\n",
      "Epochs: 9 batch_loss: 0.2385\n",
      "Epochs: 9 batch_loss: 0.2970\n",
      "Epochs: 9 batch_loss: 0.2993\n",
      "Epochs: 9 batch_loss: 0.2574\n",
      "Epochs: 9 batch_loss: 0.2994\n",
      "Epochs: 9 batch_loss: 0.2901\n",
      "Epochs: 9 batch_loss: 0.2647\n",
      "Epochs: 9 batch_loss: 0.2505\n",
      "Epochs: 9 batch_loss: 0.2746\n",
      "Epochs: 9 batch_loss: 0.2610\n",
      "Epochs: 9 batch_loss: 0.2707\n",
      "Epochs: 9 batch_loss: 0.2361\n",
      "Epochs: 9 batch_loss: 0.2772\n",
      "Epochs: 9 batch_loss: 0.2783\n",
      "Epochs: 9 batch_loss: 0.2727\n",
      "Epochs: 9 batch_loss: 0.2713\n",
      "Epochs: 9 batch_loss: 0.2775\n",
      "Epochs: 9 batch_loss: 0.2426\n",
      "Epochs: 9 batch_loss: 0.2469\n",
      "Epochs: 9 batch_loss: 0.3296\n",
      "Epochs: 9 batch_loss: 0.2613\n",
      "Epochs: 9 batch_loss: 0.2630\n",
      "Epochs: 9 batch_loss: 0.3074\n",
      "Epochs: 9 batch_loss: 0.2694\n",
      "Epochs: 9 batch_loss: 0.2417\n",
      "Epochs: 9 batch_loss: 0.2320\n",
      "Epochs: 9 batch_loss: 0.2263\n",
      "Epochs: 9 batch_loss: 0.2521\n",
      "Epochs: 9 batch_loss: 0.2329\n",
      "Epochs: 9 batch_loss: 0.2683\n",
      "Epochs: 9 batch_loss: 0.2899\n",
      "Epochs: 9 batch_loss: 0.2581\n",
      "Epochs: 9 batch_loss: 0.2299\n",
      "Epochs: 9 batch_loss: 0.2434\n",
      "Epochs: 9 batch_loss: 0.2598\n",
      "Epochs: 9 batch_loss: 0.1992\n",
      "Epochs: 9 batch_loss: 0.2646\n",
      "Epochs: 9 batch_loss: 0.2395\n",
      "Epochs: 9 batch_loss: 0.2802\n",
      "Epochs: 9 batch_loss: 0.2483\n",
      "Epochs: 9 batch_loss: 0.2088\n",
      "Epochs: 9 batch_loss: 0.2834\n",
      "Epochs: 9 batch_loss: 0.2982\n",
      "Epochs: 9 batch_loss: 0.2872\n",
      "Epochs: 9 batch_loss: 0.2512\n",
      "Epochs: 9 batch_loss: 0.2121\n",
      "Epochs: 9 batch_loss: 0.2151\n",
      "Epochs: 9 batch_loss: 0.2414\n",
      "Epochs: 9 batch_loss: 0.2889\n",
      "Epochs: 9 batch_loss: 0.2132\n",
      "Epochs: 9 batch_loss: 0.2841\n",
      "Epochs: 9 batch_loss: 0.2917\n",
      "Epochs: 9 batch_loss: 0.2312\n",
      "Epochs: 9 batch_loss: 0.2719\n",
      "Epochs: 9 batch_loss: 0.2683\n",
      "Epochs: 9 batch_loss: 0.2625\n",
      "Epochs: 9 batch_loss: 0.2528\n",
      "Epochs: 9 batch_loss: 0.2572\n",
      "Epochs: 9 batch_loss: 0.2306\n",
      "Epochs: 9 batch_loss: 0.2284\n",
      "Epochs: 9 batch_loss: 0.2508\n",
      "Epochs: 9 batch_loss: 0.2399\n",
      "Epochs: 9 batch_loss: 0.2545\n",
      "Epochs: 9 batch_loss: 0.2383\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 10\n",
    "log_every = 5\n",
    "steps_per_epoch = len(pairs) // BATCH_SIZE\n",
    "loss_list = []\n",
    "\n",
    "for e in range(1, EPOCHS):\n",
    "    \n",
    "    total_loss = 0.0\n",
    "    enc_hidden = encoder.init_hidden()\n",
    "    \n",
    "    for idx, (input_tensor, target_tensor) in enumerate(dataset.take(steps_per_epoch)):\n",
    "        batch_loss = train_step(input_tensor, target_tensor, hidden)\n",
    "        total_loss += batch_loss\n",
    "        \n",
    "        if idx % log_every == 0:\n",
    "            loss_list.append(batch_loss)\n",
    "            print(\"Epochs: {} batch_loss: {:.4f}\".format(e, batch_loss))\n",
    "            checkpoint(encoder, 'encoder5')\n",
    "            checkpoint(decoder, 'decoder5')\n",
    "            \n",
    "    if e % 2 == 0:\n",
    "        print(\"Epochs: {}/{} total_loss: {:.4f}\".format(\n",
    "        e, EPOCHS, total_loss / steps_per_epoch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JuswAWMYqdME"
   },
   "outputs": [],
   "source": [
    "def translate(sentence, max_length=10):\n",
    "    result = ''\n",
    "    attention_plot = np.zeros((10,10))\n",
    "    sentence = normalizeString(sentence)\n",
    "    sentence = sentencetoIndexes(sentence, input_lang)\n",
    "    sentence = keras.preprocessing.sequence.pad_sequences([sentence],padding='post',\n",
    "                                                      maxlen=max_length, truncating='post')\n",
    "    \n",
    "    encoder_hidden = hidden = [tf.zeros((1, 256))]\n",
    "    \n",
    "    enc_out, enc_hidden = encoder(sentence, encoder_hidden)\n",
    "    \n",
    "    dec_hidden = enc_hidden\n",
    "    SOS_tensor = np.array([SOS_token])\n",
    "    dec_input = tf.squeeze(tf.expand_dims([SOS_tensor], 1), -1)\n",
    "    \n",
    "    for tx in range(max_length):\n",
    "        dec_out, dec_hidden, attn_weights = decoder(dec_input,\n",
    "                                                   dec_hidden, enc_out)\n",
    "        attn_weights = tf.reshape(attn_weights, (-1, ))\n",
    "        attention_plot[tx] = attn_weights.numpy()\n",
    "        pred = tf.argmax(dec_out, axis=1).numpy()\n",
    "        result += output_lang.int2word[pred[0]] + \" \"\n",
    "        if output_lang.int2word[pred[0]] == \"EOS\":\n",
    "            break\n",
    "        dec_input = tf.expand_dims(pred, axis=1)\n",
    "    return result, attention_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "r7mmzYUIqdMI",
    "outputId": "e78bcf6c-9cea-4d8a-880a-27a4acabc95e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "do i need someone to help me ? EOS \n"
     ]
    }
   ],
   "source": [
    "sentence = \"j'ai besoin de quelqu'un pour m'aider ?\"\n",
    "pred, attn_weights = translate(sentence)\n",
    "print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-s9cnSvUxNIC"
   },
   "outputs": [],
   "source": [
    "def plot_attention(attention, sentence, predicted_sentence):\n",
    "    sentence = normalizeString(listToString(sentence))\n",
    "    fig = plt.figure(figsize=(10,10))\n",
    "    ax = fig.add_subplot(1, 1, 1)\n",
    "    ax.matshow(attention, cmap='viridis')\n",
    "\n",
    "    fontdict = {'fontsize': 14}\n",
    "\n",
    "    ax.set_xticklabels([''] + Convert(sentence), fontdict=fontdict, rotation=90)\n",
    "    ax.set_yticklabels([''] + predicted_sentence, fontdict=fontdict)\n",
    "\n",
    "    ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "    ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xpf4T5z_3JP4"
   },
   "outputs": [],
   "source": [
    "from matplotlib import ticker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 324
    },
    "colab_type": "code",
    "id": "5A9xpAf6xsgL",
    "outputId": "fa47f721-b6e9-4a46-84e2-e402738e7bdc"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "attn_weights = attn_weights[:len(pred.split(' ')), :len(sentence.split(' '))]\n",
    "plot_attention(attn_weights, sentence.split(), pred.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-51-f59213da22cb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'model.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "model.load_weights('model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yROfA7newSua"
   },
   "outputs": [],
   "source": [
    "encoder=models.load_weights('encoder.h5')\n",
    "decoder=load_model('decoder.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5vDXB800z9GC"
   },
   "outputs": [],
   "source": [
    "from keras import models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.models.load_weights(encoder.h5, by_name=False, skip_mismatch=False, options=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "go .\n"
     ]
    }
   ],
   "source": [
    "print(pairs[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "machine translation tensorflow orig.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "azureml_py36_tensorflow",
   "language": "python",
   "name": "conda-env-azureml_py36_tensorflow-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
